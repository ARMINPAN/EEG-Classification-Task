{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CI Project",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/zyQ0iL3vrZfAV7ZEJDzQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vGvaVdOgfdAt"
      },
      "outputs": [],
      "source": [
        "# EEG Classification BCI Task\n",
        "# Computational Intelligence Course Final Project\n",
        "# Armin Panjehpour - 98101288"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/CI_Project_Dataset/'  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzJtcbH1cBbd",
        "outputId": "08c21836-9429-4821-fb4d-6ff038ed3045"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import fft"
      ],
      "metadata": {
        "id": "kiGddLPUcPHC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "Data = mat = loadmat('/content/gdrive/MyDrive/Colab Notebooks/CI_Project_Dataset/CI_Project_data.mat')\n",
        "print(Data.keys())\n",
        "print('Dataset loaded!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-gTSxuddtGM",
        "outputId": "93c91454-38d3-4045-be6d-af70c16edc5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'TestData', 'TrainData', 'TrainLabel'])\n",
            "Dataset loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Test Dataset\n",
        "Train_Data = Data['TrainData']\n",
        "Test_Data = Data['TestData']\n",
        "\n",
        "# Training Dataset Labels\n",
        "Train_Label = Data['TrainLabel']\n",
        "\n",
        "# Dataset Size\n",
        "print('Train_Data: ',Train_Data.shape)\n",
        "print('Test_Data: ',Test_Data.shape)\n",
        "print('Train_Label: ',Train_Label.shape)\n",
        "\n",
        "\n",
        "print('Train\\Test Data Created!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lnmmcb9gjNG",
        "outputId": "53c860f8-3252-4641-8965-c47189940ff3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Data:  (30, 384, 120)\n",
            "Test_Data:  (30, 384, 40)\n",
            "Train_Label:  (1, 120)\n",
            "Train\\Test Data Created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling Rate\n",
        "\n",
        "Trial_Time = 1.5 # in seconds\n",
        "Fs = Train_Data.shape[1]/Trial_Time\n",
        "\n",
        "print('Sampling Rate is: ',Fs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XDi6kclhKq-",
        "outputId": "c11c3aaf-6dca-4ccc-d6bd-b3ed692fbcd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling Rate is:  256.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################ Calculate Different Features for Each Channel ############################################"
      ],
      "metadata": {
        "id": "wgcPg7itlTn0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Var_Feature(data):\n",
        "  # variance of each channel\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  var = np.var(data, axis=1)\n",
        "  return var"
      ],
      "metadata": {
        "id": "5L9BWbPDliHX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def amp_hist_Feature(data, n_bins, min_amp, max_amp):\n",
        "  # amplitude histogram\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  n_channels = data.shape[0]\n",
        "  [x_selec, y_selec, z_selec] = np.asarray(np.where((np.logical_and(1 <= data, data <= 2)) == True))\n",
        "  hist_vals = []\n",
        "  for i in range(n_channels):\n",
        "    selected_chan = np.asarray(np.where(x_selec == i))\n",
        "    selected_chan_data = data[x_selec[selected_chan],y_selec[selected_chan],z_selec[selected_chan]]\n",
        "    hist_selected_chan = np.histogram(selected_chan_data, n_bins)[0]\n",
        "    hist_vals.append(hist_selected_chan)\n",
        "  \n",
        "  return np.asarray(hist_vals)"
      ],
      "metadata": {
        "id": "uGTQ_F1TmfzZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AR_Coeffs(data, order):\n",
        "  # autoregressive model coefficients\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "  Y = np.zeros((n_channels, n_samples-order, n_trials))\n",
        "  Y = data[:, order:n_samples, :]\n",
        "\n",
        "  X = np.zeros((n_trials, n_channels, n_samples-order, order+1))\n",
        "  X[:,:,:,0] = 1\n",
        "\n",
        "  Coeffs = np.zeros((n_trials, n_channels, order+1))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      for k in range(n_samples-order):\n",
        "        for z in range(order):\n",
        "          if(k-z >= 0):\n",
        "            X[i,j,k,order-z-1] = data[j,k-z,i]\n",
        "          else:\n",
        "            X[i,j,k,order-z-1] = 0\n",
        "\n",
        "      a = ((X[i,j,:,:].T @ X[i,j,:,:]) + np.asarray(0.00001*np.random.random((order+1, order+1))))\n",
        "      Coeffs[i,j,:] = np.linalg.inv(a) @ (X[i,j,:,:].T) @ Y[j,:,i]\n",
        "\n",
        "  return Coeffs"
      ],
      "metadata": {
        "id": "m8hhHtEvAB8n"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FF_Feature(data):\n",
        "  # form factor\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  signal_std = np.std(data, axis=1)\n",
        "  first_deriv_Std = np.std(np.diff(data, axis=1), axis=1)\n",
        "  second_deriv_Std = np.std(np.diff(np.diff(data, axis=1), axis=1), axis=1)\n",
        "  FF = (second_deriv_Std/first_deriv_Std)/(first_deriv_Std/signal_std)\n",
        "\n",
        "  return FF"
      ],
      "metadata": {
        "id": "aokkYWWggFhf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cov_calculator(data1, data2):\n",
        "  # covariancce calculator between two vector signals\n",
        "  return np.sum(np.multiply(data1-np.mean(data1),data2-np.mean(data2)))/data1.shape[0]"
      ],
      "metadata": {
        "id": "ev3PfmhmlJZE"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cov_Feature(data):\n",
        "  # covariance between pairs of channels\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  cov_matrix = np.zeros((n_trials,n_channels,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      for k in range(n_channels):\n",
        "        selected_data_ch1 = data[j,:,i]\n",
        "        selected_data_ch2 = data[k,:,i]\n",
        "        cov_matrix[i,j,k] = cov_calculator(selected_data_ch1,selected_data_ch2)\n",
        "\n",
        "  return cov_matrix"
      ],
      "metadata": {
        "id": "ctsYYd4QjaEq"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fft_calculator(data, Fs):\n",
        "  # calculate single side band fft of a vector signal\n",
        "  L = data.shape[0]\n",
        "  fft_data = fft(data)\n",
        "  P2 = abs(fft_data/L)\n",
        "  P1 = P2[0:L/2+1]\n",
        "  P1[1:-1] = 2*P1[1:-1]\n",
        "\n",
        "  f = Fs*np.arange(0,L/2+1)/L\n",
        "\n",
        "  return f, P1"
      ],
      "metadata": {
        "id": "uYD2IzhnopmV"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_freq_Feature(data, Fs):\n",
        "  # find the frequency with the maximum amplitude for each channel\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  \n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  max_freq = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      f, max_freq[i,j] = fft_calculator(selected_data, Fs)\n",
        "\n",
        "  return f, max_freq"
      ],
      "metadata": {
        "id": "UBZvqLIenhD4"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_freq_Feature(data, Fs):\n",
        "  # find the normalized weighted mean of frequencies\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  mean_freq = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      f, fft_selected_data = fft_calculator(selected_data, Fs)\n",
        "\n",
        "      mean_freq[i,j] = np.multiply(f, fft_selected_data)/np.sum(fft_selected_data)\n",
        "\n",
        "\n",
        "  return f, mean_freq"
      ],
      "metadata": {
        "id": "wTsngFbqu4MV"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################ Apply the Feature Functions on Training Data ############################################"
      ],
      "metadata": {
        "id": "w98tO9jiwwj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate variance of each trail and channel\n",
        "var_feature = Var_Feature(Train_Data)"
      ],
      "metadata": {
        "id": "BzOTtCamzWIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}