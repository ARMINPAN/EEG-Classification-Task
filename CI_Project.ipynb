{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGvaVdOgfdAt"
      },
      "outputs": [],
      "source": [
        "# EEG Classification BCI Task\n",
        "# Computational Intelligence Course Final Project\n",
        "# Armin Panjehpour - 98101288"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzJtcbH1cBbd",
        "outputId": "b094ccb7-c2be-4541-9da4-d788743aae48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Accessing google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/CI_Project_Dataset/'  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "kiGddLPUcPHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import fft\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-gTSxuddtGM",
        "outputId": "e63337e8-bb1c-4ef9-ff8e-74844496d49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'TestData', 'TrainData', 'TrainLabel'])\n",
            "Dataset loaded!\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset\n",
        "Data = mat = loadmat('/content/gdrive/MyDrive/Colab Notebooks/CI_Project_Dataset/CI_Project_data.mat')\n",
        "print(Data.keys())\n",
        "print('Dataset loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lnmmcb9gjNG",
        "outputId": "4681759b-55d3-4e03-aa31-56344262bd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Data:  (30, 384, 120)\n",
            "Test_Data:  (30, 384, 40)\n",
            "Train_Label:  (120,)\n",
            "Train\\Test Data Created!\n"
          ]
        }
      ],
      "source": [
        "# Training and Test Dataset\n",
        "Train_Data = Data['TrainData']\n",
        "Test_Data = Data['TestData']\n",
        "\n",
        "# Training Dataset Labels\n",
        "Train_Label = np.squeeze(Data['TrainLabel'])-1\n",
        "\n",
        "# Dataset Size\n",
        "print('Train_Data: ',Train_Data.shape)\n",
        "print('Test_Data: ',Test_Data.shape)\n",
        "print('Train_Label: ',Train_Label.shape)\n",
        "\n",
        "\n",
        "print('Train\\Test Data Created!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XDi6kclhKq-",
        "outputId": "d919885b-707b-49a8-e3ec-df7032943958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling Rate is:  256.0\n"
          ]
        }
      ],
      "source": [
        "# Sampling Rate\n",
        "\n",
        "Trial_Time = 1.5 # in seconds\n",
        "Fs = Train_Data.shape[1]/Trial_Time\n",
        "\n",
        "print('Sampling Rate is: ',Fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgcPg7itlTn0"
      },
      "outputs": [],
      "source": [
        "############################################ Calculate Different Features for Each Channel ############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5L9BWbPDliHX"
      },
      "outputs": [],
      "source": [
        "def Var_Feature(data):\n",
        "  # variance of each channel\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  var = np.var(data, axis=1)\n",
        "  return var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uGTQ_F1TmfzZ"
      },
      "outputs": [],
      "source": [
        "def amp_hist_Feature(data, n_bins, min_amp, max_amp):\n",
        "  # amplitude histogram\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  n_channels = data.shape[0]\n",
        "  n_trials = data.shape[-1]\n",
        "  \n",
        "  hist_vals = np.zeros((n_channels,n_trials,n_bins))\n",
        "  for i in range(n_channels):\n",
        "    for j in range(n_trials):\n",
        "      in_range = np.asarray(np.where((np.logical_and(1 <= data[i,:,j], data[i,:,j] <= 2)) == True))\n",
        "      selected_chan_data = data[i, in_range, j]\n",
        "      hist_vals[i,j,:] = np.histogram(selected_chan_data, n_bins)[0]\n",
        "      \n",
        "  \n",
        "  return np.asarray(hist_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m8hhHtEvAB8n"
      },
      "outputs": [],
      "source": [
        "def AR_Coeffs(data, order):\n",
        "  # autoregressive model coefficients\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "  Y = np.zeros((n_channels, n_samples-order, n_trials))\n",
        "  Y = data[:, order:n_samples, :]\n",
        "\n",
        "  X = np.zeros((n_trials, n_channels, n_samples-order, order+1))\n",
        "  X[:,:,:,0] = 1\n",
        "\n",
        "  Coeffs = np.zeros((n_trials, n_channels, order+1))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      for k in range(n_samples-order):\n",
        "        for z in range(order):\n",
        "          if(k-z >= 0):\n",
        "            X[i,j,k,order-z-1] = data[j,k-z,i]\n",
        "          else:\n",
        "            X[i,j,k,order-z-1] = 0\n",
        "\n",
        "      a = ((X[i,j,:,:].T @ X[i,j,:,:]) + np.asarray(0.00001*np.random.random((order+1, order+1))))\n",
        "      Coeffs[i,j,:] = np.linalg.inv(a) @ (X[i,j,:,:].T) @ Y[j,:,i]\n",
        "\n",
        "  return Coeffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aokkYWWggFhf"
      },
      "outputs": [],
      "source": [
        "def FF_Feature(data):\n",
        "  # form factor\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  signal_std = np.std(data, axis=1)\n",
        "  first_deriv_Std = np.std(np.diff(data, axis=1), axis=1)\n",
        "  second_deriv_Std = np.std(np.diff(np.diff(data, axis=1), axis=1), axis=1)\n",
        "  FF = (second_deriv_Std/first_deriv_Std)/(first_deriv_Std/signal_std)\n",
        "\n",
        "  return FF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ev3PfmhmlJZE"
      },
      "outputs": [],
      "source": [
        "def cov_calculator(data1, data2):\n",
        "  # covariancce calculator between two vector signals\n",
        "  return np.sum(np.multiply(data1-np.mean(data1),data2-np.mean(data2)))/data1.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ctsYYd4QjaEq"
      },
      "outputs": [],
      "source": [
        "def cov_Feature(data):\n",
        "  # covariance between pairs of channels\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  cov_matrix = np.zeros((n_trials,n_channels,n_channels))\n",
        "  cov_values = np.zeros((n_trials,int((n_channels-1)*n_channels/2)))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      for k in range(j+1):\n",
        "        selected_data_ch1 = data[j,:,i]\n",
        "        selected_data_ch2 = data[k,:,i]\n",
        "        cov_values[i,j+k] = cov_calculator(selected_data_ch1,selected_data_ch2)\n",
        "\n",
        "  \n",
        "  return cov_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uYD2IzhnopmV"
      },
      "outputs": [],
      "source": [
        "def fft_calculator(data, Fs):\n",
        "  # calculate single side band fft of a vector signal\n",
        "  L = data.shape[0]\n",
        "  fft_data = fft(data)\n",
        "  P2 = np.abs(fft_data/L)\n",
        "  P1 = P2[0:int(L/2)+1]\n",
        "  P1[1:-1] = 2*P1[1:-1]\n",
        "\n",
        "  f = Fs*np.arange(0,L/2+1)/L\n",
        "\n",
        "  return f, P1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UBZvqLIenhD4"
      },
      "outputs": [],
      "source": [
        "def max_freq_Feature(data, Fs):\n",
        "  # find the frequency with the maximum amplitude for each channel\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  \n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  max_freq = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      f, fft_selected_data = fft_calculator(selected_data, Fs)\n",
        "      max_freq[i,j] = f[np.argmax(fft_selected_data)]\n",
        "\n",
        "  return f, max_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wTsngFbqu4MV"
      },
      "outputs": [],
      "source": [
        "def mean_freq_Feature(data, Fs):\n",
        "  # find the normalized weighted mean of frequencies\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  mean_freq = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      f, fft_selected_data = fft_calculator(selected_data, Fs)\n",
        "\n",
        "      mean_freq[i,j] = np.sum(np.multiply(f, fft_selected_data))/np.sum(fft_selected_data)\n",
        "\n",
        "\n",
        "  return f, mean_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w98tO9jiwwj4"
      },
      "outputs": [],
      "source": [
        "############################################ Apply the Feature Functions on Training Data ############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyIrVWl_K0fi",
        "outputId": "87044f9a-3cc8-4df4-a30c-ca11f2da665d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60,) (60,)\n"
          ]
        }
      ],
      "source": [
        "# get trial numbers of two classes\n",
        "class1_trialnum = np.squeeze(np.asarray(np.where(np.squeeze(Train_Label) == 1)))\n",
        "class2_trialnum = np.squeeze(np.asarray(np.where(np.squeeze(Train_Label) == 2)))\n",
        "\n",
        "print(class1_trialnum.shape, class2_trialnum.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzOTtCamzWIn",
        "outputId": "6a592ce3-7773-42a2-edf9-e7cab46d5a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 30, 60)\n"
          ]
        }
      ],
      "source": [
        "# calculate variance of each trail and channel - one value for each channel and trial\n",
        "var_feature = Var_Feature(Train_Data)\n",
        "\n",
        "n_class = 2\n",
        "var_feature_classes = np.zeros((n_class,var_feature.shape[0],int(var_feature.shape[1]/n_class)))\n",
        "\n",
        "var_feature_classes[0,:,:] = var_feature[:,class1_trialnum]\n",
        "var_feature_classes[1,:,:] = var_feature[:,class2_trialnum]\n",
        "\n",
        "\n",
        "print(var_feature_classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9fiycA4z57y",
        "outputId": "d5e97fe0-21b6-4498-8802-226f02d8110a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 30, 60, 5)\n"
          ]
        }
      ],
      "source": [
        "# calculate amplitude histogram - nbin values for each channel\n",
        "n_bins = 5\n",
        "min_amp = -10\n",
        "max_amp = 10\n",
        "hist_feature = amp_hist_Feature(Train_Data, n_bins, min_amp, max_amp)\n",
        "\n",
        "n_class = 2\n",
        "hist_feature_classes = np.zeros((n_class,hist_feature.shape[0],int(hist_feature.shape[1]/n_class),hist_feature.shape[-1]))\n",
        "\n",
        "hist_feature_classes[0,:,:,:] = hist_feature[:,class1_trialnum,:]\n",
        "hist_feature_classes[1,:,:,:] = hist_feature[:,class2_trialnum,:]\n",
        "\n",
        "print(hist_feature_classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1zdHj5X0hgJ",
        "outputId": "bd1eec78-b2ea-4b49-b9e6-c080117d55be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 30, 60)\n"
          ]
        }
      ],
      "source": [
        "# calculate Form Factor -  one value for each channel and trial\n",
        "FF_feature = FF_Feature(Train_Data)\n",
        "\n",
        "n_class = 2\n",
        "FF_feature_classes = np.zeros((n_class,FF_feature.shape[0],int(FF_feature.shape[1]/n_class)))\n",
        "\n",
        "FF_feature_classes[0,:,:] = FF_feature[:,class1_trialnum]\n",
        "FF_feature_classes[1,:,:] = FF_feature[:,class2_trialnum]\n",
        "\n",
        "print(FF_feature_classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib3MTX3v8xFJ",
        "outputId": "2a05a58c-159a-43e5-b1f2-5d8f1ef021a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 60, 435)\n"
          ]
        }
      ],
      "source": [
        "# calculate cov_Feature -  one normalized covariance matrix for each trial\n",
        "cov_feature = cov_Feature(Train_Data)\n",
        "\n",
        "n_class = 2\n",
        "cov_feature_classes = np.zeros((n_class,int(cov_feature.shape[0]/n_class),cov_feature.shape[1]))\n",
        "\n",
        "cov_feature_classes[0,:,:] = cov_feature[class1_trialnum,:]\n",
        "cov_feature_classes[1,:,:] = cov_feature[class2_trialnum,:]\n",
        "print(cov_feature_classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R45f-I2oC1Yh",
        "outputId": "e1975a26-79c5-414c-cca6-737d79e8c765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 60, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate max_freq_Feature -  one max freq for each trail and channel\n",
        "f, max_freq_feature = max_freq_Feature(Train_Data, Fs)\n",
        "\n",
        "\n",
        "n_class = 2\n",
        "max_freq_feature_classes = np.zeros((n_class,int(max_freq_feature.shape[0]/n_class),max_freq_feature.shape[1]))\n",
        "\n",
        "max_freq_feature_classes[0,:,:] = max_freq_feature[class1_trialnum,:]\n",
        "max_freq_feature_classes[1,:,:] = max_freq_feature[class2_trialnum,:]\n",
        "\n",
        "\n",
        "print(max_freq_feature_classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ3H-Sj7JG26",
        "outputId": "ab70e181-4305-4d39-a746-799d044714a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 60, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate mean_freq_Feature -  one mean freq for each trail and channel\n",
        "f, mean_freq_feature = mean_freq_Feature(Train_Data, Fs)\n",
        "\n",
        "n_class = 2\n",
        "mean_freq_feature_classes = np.zeros((n_class,int(max_freq_feature.shape[0]/n_class),max_freq_feature.shape[1]))\n",
        "\n",
        "mean_freq_feature_classes[0,:,:] = mean_freq_feature[class1_trialnum,:]\n",
        "mean_freq_feature_classes[1,:,:] = mean_freq_feature[class2_trialnum,:]\n",
        "\n",
        "print(mean_freq_feature_classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GT3JjqkoKBD3"
      },
      "outputs": [],
      "source": [
        "def fisher_score_cal(bothclass_data,class1_data,class2_data):\n",
        "  # calculate fisher score for each channel\n",
        "  mean_bothclass = np.mean(bothclass_data)\n",
        "  mean_class1 = np.mean(class1_data)\n",
        "  mean_class2 = np.mean(class2_data)\n",
        "\n",
        "  var_class1 = np.var(class1_data)\n",
        "  var_class2 = np.var(class2_data)\n",
        "\n",
        "  score = ((mean_bothclass-mean_class1)**2 + (mean_bothclass-mean_class2)**2)/(var_class1+var_class2)\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB8B15atacnG",
        "outputId": "751df367-7956-4b97-de35-9b338f3555d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0007767337301206576"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "selected_channel =  1\n",
        "\n",
        "fisher_score_cal(cov_feature_classes,cov_feature_classes[0,:,:],cov_feature_classes[1,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it seems that non of the features give us high fisher score just by them self"
      ],
      "metadata": {
        "id": "YPLkB5v0LYHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check some features together\n",
        "group_features_class1 = np.concatenate((var_feature_classes[0,:,:].T,max_freq_feature_classes[0,:,:],mean_freq_feature_classes[0,:,:]), axis=1)\n",
        "group_features_class2 = np.concatenate((var_feature_classes[1,:,:].T,max_freq_feature_classes[1,:,:],mean_freq_feature_classes[1,:,:]), axis=1)\n",
        "group_features_both = np.concatenate((group_features_class1,group_features_class2), axis=0)\n",
        "\n",
        "# normalize feature matrices \n",
        "group_features_class1 = stats.zscore(group_features_class1, axis=1)\n",
        "group_features_class2 = stats.zscore(group_features_class2, axis=1)\n",
        "\n",
        "print(group_features_class1.shape, group_features_class2.shape, group_features_both.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfTpR_5bLO7Y",
        "outputId": "78f54b8f-d72a-4b4d-c16a-24b164a0d005"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 90) (60, 90) (120, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score\n",
        "\n",
        "# within class matrices\n",
        "S1 = np.zeros((group_features_class1.shape[1],group_features_class1.shape[1]))\n",
        "S2 = np.zeros((group_features_class2.shape[1],group_features_class2.shape[1]))\n",
        "\n",
        "n_trials = 60\n",
        "n_class = 2\n",
        "for i in range(n_trials):\n",
        "  S1 += (group_features_class1[i,:] - np.mean(group_features_class1[i,:])) @ (group_features_class1[i,:] - np.mean(group_features_class1[i,:])).T\n",
        "  S2 += (group_features_class2[i,:] - np.mean(group_features_class2[i,:])) @ (group_features_class2[i,:] - np.mean(group_features_class2[i,:])).T\n",
        "\n",
        "S1 /= n_trials\n",
        "S2 /= n_trials  \n",
        "print(S1.shape, S2.shape)\n",
        "\n",
        "Sw = S1+S2\n",
        "\n",
        "# between class matrix\n",
        "Sb = np.zeros((group_features_class1.shape[1],group_features_class1.shape[1]))\n",
        "\n",
        "mean_all = np.expand_dims(np.mean(group_features_both, axis=0), axis=1)\n",
        "mean_class1 = np.expand_dims(np.mean(group_features_class1, axis=0), axis=1)\n",
        "mean_class2 = np.expand_dims(np.mean(group_features_class2, axis=0), axis=1)\n",
        "\n",
        "print(mean_all.shape, mean_class1.shape, mean_class2.shape)\n",
        "\n",
        "Sb = ((mean_class1-mean_all) @ (mean_class1-mean_all).T) + ((mean_class2-mean_all) @ (mean_class2-mean_all).T)\n",
        "\n",
        "print(Sb.shape)\n",
        "\n",
        "# final score\n",
        "J = np.trace(Sb)/np.trace(Sw)\n",
        "print('final score is: ', J)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txo6fu6MTp9T",
        "outputId": "67f99a0e-3b83-493f-9d70-47dd5412e787"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 90) (90, 90)\n",
            "(90, 1) (90, 1) (90, 1)\n",
            "(90, 90)\n",
            "final score is:  20.725104855812365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE MLP MODEL\n",
        "\n",
        "# Setting up the layers\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Softmax\n",
        "\n",
        "input_layer_size = group_features_class1.shape[1]\n",
        "n_class = 2\n",
        "\n",
        "model = keras.Sequential([\n",
        "                      Input(shape = (input_layer_size,)), # input layer\n",
        "                      Dense(units = 128), # hidden layer one\n",
        "                      Activation(activation = tf.math.tanh),\n",
        "                      Dense(units = 32), # hidden layer two\n",
        "                      Activation(activation = tf.math.tanh),\n",
        "                      Dense(units = 2), # output layer\n",
        "                      Softmax(axis = 1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rsQjwI-Y85I",
        "outputId": "4246d88b-445a-4157-9434-b0f329f97f44"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 128)               11648     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 32)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            " softmax_5 (Softmax)         (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,842\n",
            "Trainable params: 15,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compling the model\n",
        "\n",
        "# make our model ready for training\n",
        "# 1. optimizer 2. loss function 3. metrics\n",
        "\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.SGD(learning_rate = 0.01),\n",
        "    loss = keras.losses.CategoricalCrossentropy(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "7FfyOdImbOo4"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change y to one hot labels\n",
        "# we have 2 classes, so our MLP will have 2 output neurons which one neuron \n",
        "# will be one and the others zero\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_tr_hot = to_categorical(Train_Label)\n",
        "\n",
        "print(y_tr_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPrFzslae1_m",
        "outputId": "a001bbfd-6239-4a98-e00e-7d9c8da94a9c"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "# using .fit in keras\n",
        "# inputs of .fit : 1. Train/Val Data 2. Batch Size(go over samples window size)\n",
        "# 3. Number of Epochs(number of repeatation on all samples) 4. Callbacks\n",
        "\n",
        "\n",
        "hist = model.fit(\n",
        "    group_features_both,\n",
        "    y_tr_hot,\n",
        "    batch_size = 10,\n",
        "    epochs = 200,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "15jsAIGkbRhA",
        "outputId": "32122613-493a-4649-8fa5-8246fd2e6b6e"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.5667\n",
            "Epoch 164/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.5833\n",
            "Epoch 165/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.5750\n",
            "Epoch 166/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.5917\n",
            "Epoch 167/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.5667\n",
            "Epoch 168/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.5167\n",
            "Epoch 169/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.5750\n",
            "Epoch 170/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.5750\n",
            "Epoch 171/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.5250\n",
            "Epoch 172/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.5667\n",
            "Epoch 173/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6083\n",
            "Epoch 174/200\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.5500\n",
            "Epoch 175/200\n",
            " 77/120 [==================>...........] - ETA: 0s - loss: 0.6598 - accuracy: 0.5065"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-175-6b2d40309570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_tr_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CI Project",
      "provenance": [],
      "authorship_tag": "ABX9TyOVkSYhZjssrPpLu/Ss3QdG"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}