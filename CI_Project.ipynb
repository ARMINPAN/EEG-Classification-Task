{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGvaVdOgfdAt"
      },
      "outputs": [],
      "source": [
        "# EEG Classification BCI Task\n",
        "# Computational Intelligence Course Final Project\n",
        "# Armin Panjehpour - 98101288"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzJtcbH1cBbd",
        "outputId": "91426fe6-567a-4ccb-a608-5cc830ee5fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Accessing google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/CI_Project_Dataset/'  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "kiGddLPUcPHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import fft\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from scipy import signal\n",
        "from sklearn.model_selection import KFold\n",
        "import scipy \n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-gTSxuddtGM",
        "outputId": "3210c0c6-b8d0-42e7-f0be-22f181dbd81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'TestData', 'TrainData', 'TrainLabel'])\n",
            "Dataset loaded!\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset\n",
        "Data = mat = loadmat('/content/gdrive/MyDrive/Colab Notebooks/CI_Project_Dataset/CI_Project_data.mat')\n",
        "print(Data.keys())\n",
        "print('Dataset loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lnmmcb9gjNG",
        "outputId": "69a07af9-f06f-4702-86af-8bf04cb99aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Data:  (30, 384, 120)\n",
            "Test_Data:  (30, 384, 40)\n",
            "Train_Label:  (120,)\n",
            "Train\\Test Data Created!\n"
          ]
        }
      ],
      "source": [
        "# Training and Test Dataset\n",
        "\n",
        "Train_Data = Data['TrainData']\n",
        "Test_Data = Data['TestData']\n",
        "\n",
        "# Training Dataset Labels\n",
        "Labels = np.squeeze(Data['TrainLabel'])-1\n",
        "\n",
        "# Dataset Size\n",
        "print('Train_Data: ',Train_Data.shape)\n",
        "print('Test_Data: ',Test_Data.shape)\n",
        "print('Train_Label: ',Labels.shape)\n",
        "\n",
        "\n",
        "print('Train\\Test Data Created!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XDi6kclhKq-",
        "outputId": "aa0f1a90-c7d2-47ec-e1d0-706d3528cb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling Rate is:  256.0\n"
          ]
        }
      ],
      "source": [
        "# Sampling Rate\n",
        "\n",
        "Trial_Time = 1.5 # in seconds\n",
        "Fs = Train_Data.shape[1]/Trial_Time\n",
        "\n",
        "print('Sampling Rate is: ',Fs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "83f3lsRYfPwy"
      },
      "outputs": [],
      "source": [
        "# different frequency bands in Hz\n",
        "Delta_freq = [0.5, 3] \n",
        "Theta_freq = [4, 7]\n",
        "Alpha_freq = [8, 12]\n",
        "betha_freq = [12, 30]\n",
        "Gamma_freq = [30, 100]\n",
        "\n",
        "selected_frequency_band = betha_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaX7yUV5kEt2",
        "outputId": "355a5a80-945e-4647-a40d-9e5c77e2498b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 384, 100) (30, 384, 20) (100,) (20,)\n"
          ]
        }
      ],
      "source": [
        "# Train-Validation Split\n",
        "\n",
        "# select 20% of train data as validation data\n",
        "n_val_class1 = 10\n",
        "n_val_class2 = 10\n",
        "selected_class1 = np.random.choice(np.squeeze(np.where(Labels == 0)), size=n_val_class1, replace=False)\n",
        "selected_class2 = np.random.choice(np.squeeze(np.where(Labels == 1)), size=n_val_class2, replace=False)\n",
        "selected_valdata = np.concatenate((selected_class1, selected_class2))\n",
        "\n",
        "\n",
        "Val_data = Train_Data[:,:,selected_valdata]\n",
        "Val_Label = Labels[selected_valdata]\n",
        "Train_Data = np.delete(Train_Data, selected_valdata, axis=2)\n",
        "Train_Label = np.delete(Labels, selected_valdata)\n",
        "\n",
        "print(Train_Data.shape, Val_data.shape, Train_Label.shape, Val_Label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPGi1ZRdAoOW",
        "outputId": "ca9adb7a-2152-4f2f-f327-1ade487436dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data normalized!\n"
          ]
        }
      ],
      "source": [
        "# normalize data\n",
        "amp_norm = np.max(Train_Data, axis=(1,2))\n",
        "std_norm = np.std(Train_Data, axis=(1,2))\n",
        "\n",
        "for i in range(Train_Data.shape[0]):\n",
        "  Train_Data[i,:,:] = (Train_Data[i,:,:] - amp_norm[i])/std_norm[i]\n",
        "  Val_data[i,:,:] = (Val_data[i,:,:] - amp_norm[i])/std_norm[i]\n",
        "\n",
        "print('data normalized!') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd4SptO-edEd",
        "outputId": "c2de24f8-fae8-4122-ca4c-a7a88d3c71da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 384, 100)\n"
          ]
        }
      ],
      "source": [
        "# Export different bands of data \n",
        "\n",
        "# design a bandpass filter\n",
        "order = 20\n",
        "sos = signal.butter(order, selected_frequency_band, btype='bandpass', fs=Fs, output='sos')\n",
        "\n",
        "# filter the data in time dimension\n",
        "Train_Data_filtered = signal.sosfilt(sos, Train_Data, axis=1)\n",
        "Test_Data_filtered = signal.sosfilt(sos, Test_Data, axis=1)\n",
        "Val_Data_filtered = signal.sosfilt(sos, Val_data, axis=1)\n",
        "\n",
        "\n",
        "# select unfiltered or filtered data\n",
        "selected_Data = Train_Data\n",
        "selected_val_Data = Val_data\n",
        "\n",
        "print(selected_Data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgcPg7itlTn0"
      },
      "outputs": [],
      "source": [
        "############################################ Calculate Different Features for Each Channel ############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "5L9BWbPDliHX"
      },
      "outputs": [],
      "source": [
        "def Var_Feature(data):\n",
        "  # variance of each channel\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  var = np.var(data, axis=1)\n",
        "  return var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "uGTQ_F1TmfzZ"
      },
      "outputs": [],
      "source": [
        "def amp_hist_Feature(data, n_bins, min_amp, max_amp):\n",
        "  # amplitude histogram\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  n_channels = data.shape[0]\n",
        "  n_trials = data.shape[-1]\n",
        "  \n",
        "  hist_vals = np.zeros((n_channels,n_trials,n_bins))\n",
        "  for i in range(n_channels):\n",
        "    for j in range(n_trials):\n",
        "      in_range = np.asarray(np.where((np.logical_and(1 <= data[i,:,j], data[i,:,j] <= 2)) == True))\n",
        "      selected_chan_data = data[i, in_range, j]\n",
        "      hist_vals[i,j,:] = np.histogram(selected_chan_data, n_bins)[0]\n",
        "      \n",
        "  \n",
        "  return np.asarray(hist_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "m8hhHtEvAB8n"
      },
      "outputs": [],
      "source": [
        "def AR_Coeffs(data, order):\n",
        "  # autoregressive model coefficients\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "  Y = np.zeros((n_channels, n_samples-order, n_trials))\n",
        "  Y = data[:, order:n_samples, :]\n",
        "\n",
        "  X = np.zeros((n_trials, n_channels, n_samples-order, order+1))\n",
        "  X[:,:,:,0] = 1\n",
        "\n",
        "  Coeffs = np.zeros((n_trials, n_channels, order+1))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      for k in range(n_samples-order):\n",
        "        for z in range(order):\n",
        "          if(k-z >= 0):\n",
        "            X[i,j,k,order-z-1] = data[j,k-z,i]\n",
        "          else:\n",
        "            X[i,j,k,order-z-1] = 0\n",
        "\n",
        "      a = ((X[i,j,:,:].T @ X[i,j,:,:]) + np.asarray(0.00001*np.random.random((order+1, order+1))))\n",
        "      Coeffs[i,j,:] = np.linalg.inv(a) @ (X[i,j,:,:].T) @ Y[j,:,i]\n",
        "\n",
        "  return Coeffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "aokkYWWggFhf"
      },
      "outputs": [],
      "source": [
        "def FF_Feature(data):\n",
        "  # form factor\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  signal_std = np.std(data, axis=1)\n",
        "  first_deriv_Std = np.std(np.diff(data, axis=1), axis=1)\n",
        "  second_deriv_Std = np.std(np.diff(np.diff(data, axis=1), axis=1), axis=1)\n",
        "  FF = (second_deriv_Std/first_deriv_Std)/(first_deriv_Std/signal_std)\n",
        "\n",
        "  return FF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "ev3PfmhmlJZE"
      },
      "outputs": [],
      "source": [
        "def cov_calculator(data1, data2):\n",
        "  # covariancce calculator between two vector signals\n",
        "  return np.sum(np.multiply(data1-np.mean(data1),data2-np.mean(data2)))/data1.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "ctsYYd4QjaEq"
      },
      "outputs": [],
      "source": [
        "def cov_Feature(data):\n",
        "  # covariance between pairs of channels\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  cov_matrix = np.zeros((n_trials,n_channels,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      for k in range(n_channels):\n",
        "        selected_data_ch1 = data[j,:,i]\n",
        "        selected_data_ch2 = data[k,:,i]\n",
        "        cov_matrix[i,j,k] = cov_calculator(selected_data_ch1,selected_data_ch2)\n",
        "\n",
        "  \n",
        "  return cov_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "mQYtwf1ziVp9"
      },
      "outputs": [],
      "source": [
        "def kurtosis_Feature(data):\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  kurtosis = np.zeros((n_trials,n_channels))\n",
        "\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      kurtosis[i,j] = stats.kurtosis(selected_data)\n",
        "\n",
        "\n",
        "  return kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "uYD2IzhnopmV"
      },
      "outputs": [],
      "source": [
        "def fft_calculator(data, Fs):\n",
        "  # calculate single side band fft of a vector signal\n",
        "  L = data.shape[0]\n",
        "  fft_data = fft(data)\n",
        "  P2 = np.abs(fft_data/L)\n",
        "  P1 = P2[0:int(L/2)+1]\n",
        "  P1[1:-1] = 2*P1[1:-1]\n",
        "\n",
        "  f = Fs*np.arange(0,L/2+1)/L\n",
        "\n",
        "  return f, P1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "UBZvqLIenhD4"
      },
      "outputs": [],
      "source": [
        "def max_freq_Feature(data, Fs):\n",
        "  # find the frequency with the maximum amplitude for each channel\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "  \n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  max_freq = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      f, fft_selected_data = fft_calculator(selected_data, Fs)\n",
        "      max_freq[i,j] = f[np.argmax(fft_selected_data)]\n",
        "\n",
        "  return f, max_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "wTsngFbqu4MV"
      },
      "outputs": [],
      "source": [
        "def mean_freq_Feature(data, Fs):\n",
        "  # find the normalized weighted mean of frequencies\n",
        "  # dim1: channel number, dim2: time, dim3: trial number\n",
        "\n",
        "  n_trials = data.shape[-1]\n",
        "  n_samples = data.shape[1]\n",
        "  n_channels = data.shape[0]\n",
        "\n",
        "  mean_freq = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = data[j,:,i]\n",
        "      f, fft_selected_data = fft_calculator(selected_data, Fs)\n",
        "\n",
        "      mean_freq[i,j] = np.sum(np.multiply(f, fft_selected_data))/np.sum(fft_selected_data)\n",
        "\n",
        "\n",
        "  return f, mean_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "wJkYYuxpC4A2"
      },
      "outputs": [],
      "source": [
        "# each band energy\n",
        "def band_energy_Feature(raw_data, Fs):\n",
        "  n_trials = raw_data.shape[-1]\n",
        "  n_samples = raw_data.shape[1]\n",
        "  n_channels = raw_data.shape[0]\n",
        "  n_bands = 5\n",
        "\n",
        "  band_energy = np.zeros((n_trials,n_channels,n_bands))\n",
        "  freqs = np.array([[0.5, 3], [4, 7], [8, 12], [12, 30], [30, 100]])\n",
        "\n",
        "\n",
        "  # energy of all bands\n",
        "\n",
        "  denum = np.zeros((n_trials,n_channels))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      # sum over all energy bands\n",
        "      for k in range(n_bands):\n",
        "        # design a bandpass filter\n",
        "        selected_frequency_band = freqs[k,:]\n",
        "        order = 20\n",
        "        sos = signal.butter(order, selected_frequency_band, 'bandpass', fs=Fs, output='sos')\n",
        "\n",
        "        # filter the data in time dimension\n",
        "        Data_filtered = signal.sosfilt(sos, raw_data[j,:,i])\n",
        "\n",
        "        f, fft_selected_data = fft_calculator(Data_filtered, Fs)\n",
        "\n",
        "        denum[i,j] += np.sum(np.power(fft_selected_data, 2))\n",
        "\n",
        "    \n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = raw_data[j,:,i]\n",
        "      for kk in range(n_bands):\n",
        "        # design a bandpass filter\n",
        "        selected_frequency_band = freqs[kk,:]\n",
        "        order = 20\n",
        "        sos = signal.butter(order, selected_frequency_band, 'bandpass', fs=Fs, output='sos')\n",
        "\n",
        "        # filter the data in time dimension\n",
        "        Data_filtered = signal.sosfilt(sos, selected_data)\n",
        "\n",
        "        f, fft_selected_data = fft_calculator(Data_filtered, Fs)\n",
        "\n",
        "        # energy of the selected frequency band\n",
        "        num = np.sum(np.power(fft_selected_data, 2))\n",
        "\n",
        "        print(i,j,k)\n",
        "        band_energy[i,j,kk] = num/denum[i,j]\n",
        "\n",
        "\n",
        "  return band_energy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# each band energy\n",
        "def band_energy_Feature1(x, fs):\n",
        "\n",
        "  freqs = np.array([[0.5, 3], [4, 7], [8, 12], [12, 30], [30, 100]])\n",
        "\n",
        "  n_trials = x.shape[-1]\n",
        "  n_samples = x.shape[1]\n",
        "  n_channels = x.shape[0]\n",
        "  n_bands = 5\n",
        "  psd = np.zeros((n_trials,n_channels,n_bands))\n",
        "\n",
        "  for i in range(n_trials):\n",
        "    for j in range(n_channels):\n",
        "      selected_data = x[j,:,i]\n",
        "      for k in range(n_bands):\n",
        "        fmin = freqs[k,0]\n",
        "        fmax = freqs[k,1]\n",
        "        f, Pxx = scipy.signal.periodogram(selected_data, fs=fs)\n",
        "        ind_min = scipy.argmax(f > fmin) - 1\n",
        "        ind_max = scipy.argmax(f > fmax) - 1\n",
        "        psd[i,j,k] = scipy.trapz(Pxx[ind_min: ind_max], f[ind_min: ind_max])\n",
        "        \n",
        "  return psd"
      ],
      "metadata": {
        "id": "YU-AIbpBjxBQ"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "vtQ2pN7gzbjC",
        "outputId": "514a0a2f-b24a-4947-e055-12253dbea6dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8c0d54d650>]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "############################################ Averaged FFT over all trials and channels ############################################\n",
        "f, fffft = fft_calculator(Train_Data_filtered[10,:,1], Fs)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
        "ax.plot(f, fffft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "w98tO9jiwwj4"
      },
      "outputs": [],
      "source": [
        "############################################ Apply the Feature Functions on Training Data ############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyIrVWl_K0fi",
        "outputId": "4f559d33-5e75-4372-b0e5-1c3bfe614ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50,) (50,) (10,) (10,)\n"
          ]
        }
      ],
      "source": [
        "# get trial numbers of two classes\n",
        "class1_trialnum = np.squeeze(np.asarray(np.where(np.squeeze(Train_Label) == 0)))\n",
        "class2_trialnum = np.squeeze(np.asarray(np.where(np.squeeze(Train_Label) == 1)))\n",
        "\n",
        "class1_trialnum_val = np.squeeze(np.asarray(np.where(np.squeeze(Val_Label) == 0)))\n",
        "class2_trialnum_val = np.squeeze(np.asarray(np.where(np.squeeze(Val_Label) == 1)))\n",
        "\n",
        "print(class1_trialnum.shape, class2_trialnum.shape, class1_trialnum_val.shape, class2_trialnum_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merged features\n",
        "merged = []\n",
        "merged_val = []"
      ],
      "metadata": {
        "id": "l-gdazPQQ6E1"
      },
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzOTtCamzWIn",
        "outputId": "cf5c2e9f-3fc6-4348-c9bb-9ddd65cbe49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30)\n",
            "(2, 10, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate variance of each trail and channel - one value for each channel and trial for train data\n",
        "var_feature = Var_Feature(selected_Data)\n",
        "\n",
        "n_class = 2\n",
        "var_feature_classes = np.zeros((n_class,int(var_feature.shape[1]/n_class),var_feature.shape[0]))\n",
        "\n",
        "var_feature_classes[0,:,:] = var_feature.T[class2_trialnum,:]\n",
        "var_feature_classes[1,:,:] = var_feature.T[class2_trialnum,:]\n",
        "merged.append(var_feature_classes)\n",
        "\n",
        "print(var_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "var_feature_val = Var_Feature(selected_val_Data)\n",
        "\n",
        "n_class = 2\n",
        "var_feature_classes_val = np.zeros((n_class,int(var_feature_val.shape[1]/n_class),var_feature_val.shape[0]))\n",
        "\n",
        "var_feature_classes_val[0,:,:] = var_feature_val.T[class1_trialnum_val,:]\n",
        "var_feature_classes_val[1,:,:] = var_feature_val.T[class2_trialnum_val,:]\n",
        "merged_val.append(var_feature_classes_val)\n",
        "\n",
        "\n",
        "print(var_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9fiycA4z57y",
        "outputId": "78fadfaf-6a30-496b-e63f-2e818fcf80b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 30, 50, 5)\n",
            "(2, 30, 10, 5)\n"
          ]
        }
      ],
      "source": [
        "# calculate amplitude histogram - nbin values for each channel for training data\n",
        "n_bins = 5\n",
        "min_amp = -10\n",
        "max_amp = 10\n",
        "hist_feature = amp_hist_Feature(selected_Data, n_bins, min_amp, max_amp)\n",
        "\n",
        "n_class = 2\n",
        "hist_feature_classes = np.zeros((n_class,hist_feature.shape[0],int(hist_feature.shape[1]/n_class),hist_feature.shape[-1]))\n",
        "\n",
        "hist_feature_classes[0,:,:,:] = hist_feature[:,class1_trialnum,:]\n",
        "hist_feature_classes[1,:,:,:] = hist_feature[:,class2_trialnum,:]\n",
        "\n",
        "for i in range (hist_feature.shape[-1]):\n",
        "  merged.append(np.moveaxis(hist_feature_classes[:,:,:,i], 1, 2))\n",
        "\n",
        "print(hist_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "n_bins = 5\n",
        "min_amp = -10\n",
        "max_amp = 10\n",
        "hist_feature_val = amp_hist_Feature(selected_val_Data, n_bins, min_amp, max_amp)\n",
        "\n",
        "n_class = 2\n",
        "hist_feature_classes_val = np.zeros((n_class,hist_feature_val.shape[0],int(hist_feature_val.shape[1]/n_class),hist_feature_val.shape[-1]))\n",
        "\n",
        "hist_feature_classes_val[0,:,:,:] = hist_feature_val[:,class1_trialnum_val,:]\n",
        "hist_feature_classes_val[0,:,:,:] = hist_feature_val[:,class2_trialnum_val,:]\n",
        "\n",
        "for i in range (hist_feature_val.shape[-1]):\n",
        "  merged_val.append(np.moveaxis(hist_feature_classes_val[:,:,:,i], 1, 2))\n",
        "\n",
        "\n",
        "\n",
        "print(hist_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tYHuTLH-DHL",
        "outputId": "d9e51322-988e-44a0-9a03-e7df4cdcf792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30, 6)\n",
            "(2, 10, 30, 6)\n"
          ]
        }
      ],
      "source": [
        "# calculate AR coefficients - order values for each trail and channel\n",
        "order = 5\n",
        "ar_feature = AR_Coeffs(selected_Data, order)\n",
        "\n",
        "n_class = 2\n",
        "ar_feature_classes = np.zeros((n_class,int(ar_feature.shape[0]/n_class),ar_feature.shape[1],ar_feature.shape[-1]))\n",
        "\n",
        "ar_feature_classes[0,:,:,:] = ar_feature[class1_trialnum,:,:]\n",
        "ar_feature_classes[1,:,:,:] = ar_feature[class2_trialnum,:,:]\n",
        "\n",
        "for i in range (ar_feature.shape[-1]):\n",
        "  merged.append(ar_feature_classes[:,:,:,i])\n",
        "\n",
        "print(ar_feature_classes.shape)\n",
        "\n",
        "\n",
        "# for validation data\n",
        "order = 5\n",
        "ar_feature_val = AR_Coeffs(selected_val_Data, order)\n",
        "\n",
        "n_class = 2\n",
        "ar_feature_classes_val = np.zeros((n_class,int(ar_feature_val.shape[0]/n_class),ar_feature_val.shape[1],ar_feature_val.shape[-1]))\n",
        "\n",
        "ar_feature_classes_val[0,:,:,:] = ar_feature_val[class1_trialnum_val,:,:]\n",
        "ar_feature_classes_val[1,:,:,:] = ar_feature_val[class2_trialnum_val,:,:]\n",
        "\n",
        "for i in range (ar_feature_val.shape[-1]):\n",
        "  merged_val.append(ar_feature_classes_val[:,:,:,i])\n",
        "\n",
        "print(ar_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1zdHj5X0hgJ",
        "outputId": "a05d6fa2-eb0f-468a-dc0f-b1f635f351b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30)\n",
            "(2, 10, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate Form Factor -  one value for each channel and trial for training data\n",
        "FF_feature = FF_Feature(selected_Data)\n",
        "\n",
        "n_class = 2\n",
        "FF_feature_classes = np.zeros((n_class,int(FF_feature.shape[1]/n_class),FF_feature.shape[0]))\n",
        "\n",
        "FF_feature_classes[0,:,:] = FF_feature.T[class1_trialnum,:]\n",
        "FF_feature_classes[1,:,:] = FF_feature.T[class2_trialnum,:]\n",
        "merged.append(FF_feature_classes)\n",
        "\n",
        "print(FF_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "FF_feature_val = FF_Feature(selected_val_Data)\n",
        "\n",
        "n_class = 2\n",
        "FF_feature_classes_val = np.zeros((n_class,int(FF_feature_val.shape[1]/n_class),FF_feature_val.shape[0]))\n",
        "\n",
        "FF_feature_classes_val[0,:,:] = FF_feature_val.T[class1_trialnum_val,:]\n",
        "FF_feature_classes_val[1,:,:] = FF_feature_val.T[class2_trialnum_val,:]\n",
        "merged_val.append(FF_feature_classes_val)\n",
        "\n",
        "print(FF_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib3MTX3v8xFJ",
        "outputId": "99437dc5-49f7-4e10-f50a-aba633e92835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30, 30)\n",
            "(2, 10, 30, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate cov_Feature -  one covariance matrix for each trial for training data\n",
        "cov_feature = cov_Feature(selected_Data)\n",
        "\n",
        "n_class = 2\n",
        "cov_feature_classes = np.zeros((n_class,int(cov_feature.shape[0]/n_class),cov_feature.shape[1],cov_feature.shape[1]))\n",
        "\n",
        "cov_feature_classes[0,:,:] = cov_feature[class1_trialnum,:]\n",
        "cov_feature_classes[1,:,:] = cov_feature[class2_trialnum,:]\n",
        "\n",
        "for i in range (cov_feature.shape[1]):\n",
        "  merged.append(cov_feature_classes[:,:,:,i])\n",
        "\n",
        "\n",
        "print(cov_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "cov_feature_val = cov_Feature(selected_val_Data)\n",
        "\n",
        "n_class = 2\n",
        "cov_feature_classes_val = np.zeros((n_class,int(cov_feature_val.shape[0]/n_class),cov_feature_val.shape[1],cov_feature_val.shape[1]))\n",
        "\n",
        "cov_feature_classes_val[0,:,:] = cov_feature_val[class1_trialnum_val,:]\n",
        "cov_feature_classes_val[1,:,:] = cov_feature_val[class2_trialnum_val,:]\n",
        "\n",
        "for i in range (cov_feature_val.shape[1]):\n",
        "  merged_val.append(cov_feature_classes_val[:,:,:,i])\n",
        "\n",
        "print(cov_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH3kw21Uivlj",
        "outputId": "351a0a20-f0f0-4f7e-afa0-a0838bfbafd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30)\n",
            "(2, 10, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate kurtosis_Feature -  one number for each trial and channel\n",
        "kurt_feature = kurtosis_Feature(selected_Data)\n",
        "\n",
        "\n",
        "n_class = 2\n",
        "kurt_feature_classes = np.zeros((n_class,int(kurt_feature.shape[0]/n_class),kurt_feature.shape[1]))\n",
        "\n",
        "kurt_feature_classes[0,:,:] = kurt_feature[class1_trialnum,:]\n",
        "kurt_feature_classes[1,:,:] = kurt_feature[class2_trialnum,:]\n",
        "merged.append(kurt_feature_classes)\n",
        "\n",
        "print(kurt_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "kurt_feature_val = kurtosis_Feature(selected_val_Data)\n",
        "\n",
        "n_class = 2\n",
        "kurt_feature_classes_val = np.zeros((n_class,int(kurt_feature_val.shape[0]/n_class),kurt_feature_val.shape[1]))\n",
        "\n",
        "kurt_feature_classes_val[0,:,:] = kurt_feature_val[class1_trialnum_val,:]\n",
        "kurt_feature_classes_val[1,:,:] = kurt_feature_val[class2_trialnum_val,:]\n",
        "merged_val.append(kurt_feature_classes_val)\n",
        "\n",
        "print(kurt_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R45f-I2oC1Yh",
        "outputId": "566423dc-a582-4bca-eba1-af339c74d7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30)\n",
            "(2, 10, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate max_freq_Feature -  one max freq for each trail and channel for training data\n",
        "f, max_freq_feature = max_freq_Feature(selected_Data, Fs)\n",
        "\n",
        "\n",
        "n_class = 2\n",
        "max_freq_feature_classes = np.zeros((n_class,int(max_freq_feature.shape[0]/n_class),max_freq_feature.shape[1]))\n",
        "\n",
        "max_freq_feature_classes[0,:,:] = max_freq_feature[class1_trialnum,:]\n",
        "max_freq_feature_classes[1,:,:] = max_freq_feature[class2_trialnum,:]\n",
        "merged.append(max_freq_feature_classes)\n",
        "\n",
        "\n",
        "print(max_freq_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "f, max_freq_feature_val = max_freq_Feature(selected_val_Data, Fs)\n",
        "\n",
        "\n",
        "n_class = 2\n",
        "max_freq_feature_classes_val = np.zeros((n_class,int(max_freq_feature_val.shape[0]/n_class),max_freq_feature_val.shape[1]))\n",
        "\n",
        "max_freq_feature_classes_val[0,:,:] = max_freq_feature_val[class1_trialnum_val,:]\n",
        "max_freq_feature_classes_val[1,:,:] = max_freq_feature_val[class2_trialnum_val,:]\n",
        "merged_val.append(max_freq_feature_classes_val)\n",
        "\n",
        "print(max_freq_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ3H-Sj7JG26",
        "outputId": "c7ec132e-391b-485d-80a2-c3408a4d5ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30)\n",
            "(2, 10, 30)\n"
          ]
        }
      ],
      "source": [
        "# calculate mean_freq_Feature -  one mean freq for each trail and channel for training data\n",
        "f, mean_freq_feature = mean_freq_Feature(selected_Data, Fs)\n",
        "\n",
        "n_class = 2\n",
        "mean_freq_feature_classes = np.zeros((n_class,int(max_freq_feature.shape[0]/n_class),max_freq_feature.shape[1]))\n",
        "\n",
        "mean_freq_feature_classes[0,:,:] = mean_freq_feature[class1_trialnum,:]\n",
        "mean_freq_feature_classes[1,:,:] = mean_freq_feature[class2_trialnum,:]\n",
        "merged.append(mean_freq_feature_classes)\n",
        "\n",
        "\n",
        "print(mean_freq_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "f, mean_freq_feature_val = mean_freq_Feature(selected_val_Data, Fs)\n",
        "\n",
        "n_class = 2\n",
        "mean_freq_feature_classes_val = np.zeros((n_class,int(mean_freq_feature_val.shape[0]/n_class),mean_freq_feature_val.shape[1]))\n",
        "\n",
        "mean_freq_feature_classes_val[0,:,:] = mean_freq_feature_val[class1_trialnum_val,:]\n",
        "mean_freq_feature_classes_val[1,:,:] = mean_freq_feature_val[class2_trialnum_val,:]\n",
        "merged_val.append(mean_freq_feature_classes_val)\n",
        "\n",
        "print(mean_freq_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KeWHXA_MHkW",
        "outputId": "0881a71e-8af2-4f9a-c237-7743acdac035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: scipy.argmax is deprecated and will be removed in SciPy 2.0.0, use numpy.argmax instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: scipy.argmax is deprecated and will be removed in SciPy 2.0.0, use numpy.argmax instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: scipy.trapz is deprecated and will be removed in SciPy 2.0.0, use numpy.trapz instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 30, 5)\n",
            "(2, 10, 30, 5)\n"
          ]
        }
      ],
      "source": [
        "# selected band energy - one energy for each trail and channel for training data\n",
        "band_energy_feature = band_energy_Feature1(selected_Data, Fs)\n",
        "\n",
        "n_class = 2\n",
        "band_energy_feature_classes = np.zeros((n_class,int(band_energy_feature.shape[0]/n_class),band_energy_feature.shape[1],band_energy_feature.shape[-1]))\n",
        "band_energy_feature_classes[0,:,:,:] = band_energy_feature[class1_trialnum,:,:]\n",
        "band_energy_feature_classes[1,:,:,:] = band_energy_feature[class2_trialnum,:,:]\n",
        "\n",
        "for i in range (band_energy_feature.shape[-1]):\n",
        "  merged.append(band_energy_feature_classes[:,:,:,i])\n",
        "\n",
        "\n",
        "print(band_energy_feature_classes.shape)\n",
        "\n",
        "# for validation data\n",
        "band_energy_feature_val = band_energy_Feature1(selected_val_Data, Fs)\n",
        "\n",
        "n_class = 2\n",
        "band_energy_feature_classes_val = np.zeros((n_class,int(band_energy_feature_val.shape[0]/n_class),band_energy_feature_val.shape[1],band_energy_feature_val.shape[-1]))\n",
        "\n",
        "band_energy_feature_classes_val[0,:,:,:] = band_energy_feature_val[class1_trialnum_val,:,:]\n",
        "band_energy_feature_classes_val[1,:,:,:] = band_energy_feature_val[class2_trialnum_val,:,:]\n",
        "\n",
        "for i in range (band_energy_feature_val.shape[-1]):\n",
        "  merged_val.append(band_energy_feature_classes_val[:,:,:,i])\n",
        "\n",
        "\n",
        "print(band_energy_feature_classes_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "GT3JjqkoKBD3"
      },
      "outputs": [],
      "source": [
        "def fisher_score_cal(bothclass_data,class1_data,class2_data):\n",
        "  # calculate fisher score for each channel\n",
        "  mean_bothclass = np.mean(bothclass_data)\n",
        "  mean_class1 = np.mean(class1_data)\n",
        "  mean_class2 = np.mean(class2_data)\n",
        "\n",
        "  var_class1 = np.var(class1_data)\n",
        "  var_class2 = np.var(class2_data)\n",
        "\n",
        "  score = ((mean_bothclass-mean_class1)**2 + (mean_bothclass-mean_class2)**2)/(var_class1+var_class2)\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged[1][:,:,1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65Zk8AD7po7b",
        "outputId": "2a49b772-c299-49ce-b2fd-6d2d55717752"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 431
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(merged), len(merged_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71NeXVcDoIGu",
        "outputId": "913f5509-20fb-4ccb-f8a5-02c034e559b9"
      },
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {
        "id": "OB8B15atacnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa432cae-af4b-4e8f-a51a-c6328f9ed6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270 38\n",
            "(array([ 30,  33,  47,  48,  51,  61,  63,  64,  71,  75,  78,  79,  80,\n",
            "        87,  90,  99, 107, 109, 136, 142, 160, 167, 175, 176, 181, 184,\n",
            "       188, 207, 209, 211, 214, 237, 239, 241, 244, 257, 267, 269]),)\n"
          ]
        }
      ],
      "source": [
        "n_all_features = 9\n",
        "n_channel = 30\n",
        "fisher_score = []\n",
        "high_Fscored_features = []\n",
        "\n",
        "thresh = 0.02\n",
        "\n",
        "for i in range(n_all_features):\n",
        "  for j in range(n_channel):\n",
        "    selected_channel =  j\n",
        "    selected_feature = merged[i][:,:,j]\n",
        "    fisher_score.append(fisher_score_cal(selected_feature, selected_feature[0], selected_feature[1]))\n",
        "    if(fisher_score[-1] > thresh):\n",
        "      high_Fscored_features.append(np.asarray([i, j]))\n",
        "  \n",
        "\n",
        "print(len(fisher_score), len(high_Fscored_features))\n",
        "\n",
        "findeds = np.where(np.asarray(fisher_score) > thresh)\n",
        "print(findeds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_class = 2\n",
        "n_class_trial = 50\n",
        "n_class_trial_val = 10\n",
        "\n",
        "all_training_features = np.zeros((n_class, n_class_trial, len(high_Fscored_features)))\n",
        "all_val_features = np.zeros((n_class, n_class_trial_val, len(high_Fscored_features)))\n",
        "\n",
        "for i in range(len(high_Fscored_features)):\n",
        "  all_training_features[:,:,i] = merged[high_Fscored_features[i][0]][:,:,high_Fscored_features[i][1]]\n",
        "  all_val_features[:,:,i] = merged_val[high_Fscored_features[i][0]][:,:,high_Fscored_features[i][1]]\n",
        "\n",
        "\n",
        "print(all_training_features.shape, all_val_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHFv31oDT7BZ",
        "outputId": "efa700b3-0fcb-4db1-cdb7-0d4fc6d9b85c"
      },
      "execution_count": 443,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 50, 38) (2, 10, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPLkB5v0LYHP"
      },
      "outputs": [],
      "source": [
        "# it seems that non of the features give us high fisher score just by them self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfTpR_5bLO7Y",
        "outputId": "faabcee8-df72-435c-a0a8-928059d7be47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 38) (50, 38) (100, 38)\n",
            "(10, 38) (10, 38) (20, 38)\n"
          ]
        }
      ],
      "source": [
        "# for training data\n",
        "# lets check some features together # \n",
        "group_features_class1 = all_training_features[0,:,:]\n",
        "group_features_class2 = all_training_features[1,:,:]\n",
        "group_features_both = np.concatenate((group_features_class1, group_features_class2), axis=0)\n",
        "\n",
        "\n",
        "# normalize feature matrices \n",
        "group_features_both = stats.zscore(group_features_both, axis=1)\n",
        "group_features_class1 = group_features_both[class1_trialnum,:]\n",
        "group_features_class2 = group_features_both[class2_trialnum,:]\n",
        "\n",
        "# shuffling\n",
        "np.random.shuffle(group_features_both)\n",
        "\n",
        "\n",
        "print(group_features_class1.shape, group_features_class2.shape, group_features_both.shape)\n",
        "\n",
        "# for validation\n",
        "group_features_class1_val = all_val_features[0,:,:]\n",
        "group_features_class2_val = all_val_features[1,:,:]\n",
        "group_features_both_val = np.concatenate((group_features_class1_val, group_features_class2_val), axis=0)\n",
        "\n",
        "# normalize feature matrices \n",
        "group_features_both_val = stats.zscore(group_features_both_val, axis=1)\n",
        "group_features_class1_val = group_features_both_val[class1_trialnum_val,:]\n",
        "group_features_class2_val = group_features_both_val[class2_trialnum_val,:]\n",
        "\n",
        "# shuffling\n",
        "np.random.shuffle(group_features_both_val)\n",
        "\n",
        "\n",
        "print(group_features_class1_val.shape, group_features_class2_val.shape, group_features_both_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txo6fu6MTp9T",
        "outputId": "92166110-c51a-49f8-c67d-e3ba9d706e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final score is:  0.001084630669889111\n",
            "final score is:  0.0011361490034796958\n",
            "final score is:  0.001174032991086809\n",
            "final score is:  0.0015853282961045176\n",
            "final score is:  0.001332786201899719\n",
            "final score is:  0.001660993303208666\n",
            "final score is:  0.0015046181868979495\n",
            "final score is:  0.0016602302300374582\n",
            "final score is:  0.0016659855840180221\n",
            "final score is:  0.0011816582155863746\n",
            "final score is:  0.001677236609783469\n",
            "final score is:  0.001647204197945015\n",
            "final score is:  0.0009941715336049919\n",
            "final score is:  0.0008544946803504776\n",
            "final score is:  0.0015266781853613051\n",
            "final score is:  0.001475629620344207\n",
            "final score is:  0.0013050124897204475\n",
            "final score is:  0.0014078318363552938\n",
            "final score is:  0.0014169979214193216\n",
            "final score is:  0.0017320405179482063\n",
            "final score is:  0.0008865732582977667\n",
            "final score is:  0.0016496186246293765\n",
            "final score is:  0.0009203548614415533\n",
            "final score is:  0.001531028311239124\n",
            "final score is:  0.0017218328516533296\n",
            "final score is:  0.002133080465150969\n",
            "final score is:  0.0015488083088860936\n",
            "final score is:  0.001322424687153826\n",
            "final score is:  0.001547709450290918\n",
            "final score is:  0.0016129958377993482\n",
            "final score is:  0.000902210863525792\n",
            "final score is:  0.00145220005643792\n",
            "final score is:  0.0016492106685174108\n",
            "final score is:  0.0009908627311533255\n",
            "final score is:  0.0013389223607497736\n",
            "final score is:  0.0012470066084257028\n",
            "final score is:  0.0014882516397719658\n",
            "final score is:  0.0007471509432623077\n",
            "final score is:  0.0007381612496513667\n",
            "final score is:  0.0014945539066322266\n",
            "final score is:  0.0008636900033655464\n",
            "final score is:  0.0019590793369389024\n",
            "final score is:  0.0016088627709350811\n",
            "final score is:  0.0010589446678029501\n",
            "final score is:  0.0017831471997680332\n",
            "final score is:  0.0008210803016615\n",
            "final score is:  0.0015452070113009563\n",
            "final score is:  0.0012789403028857303\n",
            "final score is:  0.001024069124963192\n",
            "final score is:  0.001054287091556157\n",
            "final score is:  0.0009127638464130587\n",
            "final score is:  0.0004991220405429221\n",
            "final score is:  0.0009655232236316231\n",
            "final score is:  0.001138196688441884\n",
            "final score is:  0.001254500462899969\n",
            "final score is:  0.0014745095502940555\n",
            "final score is:  0.0018116769418922301\n",
            "final score is:  0.0006924490549557237\n",
            "final score is:  0.0018450144994859017\n",
            "final score is:  0.001073121064736469\n",
            "final score is:  0.0016869630563060766\n",
            "final score is:  0.0014558613668165371\n",
            "final score is:  0.0015753884206076963\n",
            "final score is:  0.0015598353099885846\n",
            "final score is:  0.0011421665913349658\n",
            "final score is:  0.0009080370668091537\n",
            "final score is:  0.0018654361801914345\n",
            "final score is:  0.0009414937259296625\n",
            "final score is:  0.0017968449122824544\n",
            "final score is:  0.0018439665874795538\n",
            "final score is:  0.00123931515368035\n",
            "final score is:  0.001100573121114938\n",
            "final score is:  0.001341543904464817\n",
            "final score is:  0.0006375848245786579\n",
            "final score is:  0.0011808466983239496\n",
            "final score is:  0.0016201285358340802\n",
            "final score is:  0.001294143126003873\n",
            "final score is:  0.001477825596259565\n",
            "final score is:  0.0006440112474792382\n",
            "final score is:  0.00144437155124796\n",
            "final score is:  0.0009122507332203089\n",
            "final score is:  0.0009166541480811546\n",
            "final score is:  0.0009310821683765866\n",
            "final score is:  0.0015437106151080975\n",
            "final score is:  0.0013891261694479017\n",
            "final score is:  0.0010699623339698963\n",
            "final score is:  0.0010437315049512054\n",
            "final score is:  0.0017144715747382754\n",
            "final score is:  0.0009777647680473422\n",
            "final score is:  0.0017625342180429195\n",
            "final score is:  0.001569701484280464\n",
            "final score is:  0.0014601513586861203\n",
            "final score is:  0.000994911292672837\n",
            "final score is:  0.0014215484306422165\n",
            "final score is:  0.0010530248167835458\n",
            "final score is:  0.000560219167271474\n",
            "final score is:  0.0009601550746908172\n",
            "final score is:  0.0016845374242750392\n",
            "final score is:  0.0013272784845263777\n",
            "final score is:  0.0015989545067638094\n",
            "final score is:  0.0007682599168650846\n",
            "final score is:  0.0017192852210776346\n",
            "final score is:  0.001069787233580451\n",
            "final score is:  0.000871608602016052\n",
            "final score is:  0.0010193860497255767\n",
            "final score is:  0.00152278768534896\n",
            "final score is:  0.0013345121025222623\n",
            "final score is:  0.0015321874185369683\n",
            "final score is:  0.0007541244600179441\n",
            "final score is:  0.0010593410182955728\n",
            "final score is:  0.0014991594844931922\n",
            "final score is:  0.0013933346221518263\n",
            "final score is:  0.0017473482584564445\n",
            "final score is:  0.0014142869614383487\n",
            "final score is:  0.0013037126537169012\n",
            "final score is:  0.0016703049693929915\n",
            "final score is:  0.001720430143852321\n",
            "final score is:  0.001371921317259647\n",
            "final score is:  0.0017792499230507252\n",
            "final score is:  0.001657521257790645\n",
            "final score is:  0.0010045915733655237\n",
            "final score is:  0.0009479854941269816\n",
            "final score is:  0.0010831311796940222\n",
            "final score is:  0.0015952771388675156\n",
            "final score is:  0.0012191055890137638\n",
            "final score is:  0.0013517949481211531\n",
            "final score is:  0.001141103132163472\n",
            "final score is:  0.0017798436115726507\n",
            "final score is:  0.0011599358763727868\n",
            "final score is:  0.0008235857978797573\n",
            "final score is:  0.0018181792275111888\n",
            "final score is:  0.0012004881481648534\n",
            "final score is:  0.0012656171444026193\n",
            "final score is:  0.0017742494911826602\n",
            "final score is:  0.0009011690184203343\n",
            "final score is:  0.0017234886921087553\n",
            "final score is:  0.0008363050745771568\n",
            "final score is:  0.00141437211240042\n",
            "final score is:  0.0012389254630477324\n",
            "final score is:  0.0015840526108068236\n",
            "final score is:  0.0014916986408111414\n",
            "final score is:  0.0017489236625053378\n",
            "final score is:  0.0009489908820436181\n",
            "final score is:  0.0012949990754941145\n",
            "final score is:  0.0015085691217706758\n",
            "final score is:  0.0013713186135902405\n",
            "final score is:  0.0015513006406031556\n",
            "final score is:  0.0015554084313704262\n",
            "final score is:  0.0017864125729138613\n",
            "final score is:  0.0012033160830735288\n",
            "final score is:  0.0013237860445239706\n",
            "final score is:  0.0016917465607586323\n",
            "final score is:  0.0010891587919491551\n",
            "final score is:  0.0017058755971798075\n",
            "final score is:  0.0012170831765400832\n",
            "final score is:  0.0012240606692622744\n",
            "final score is:  0.0015937724761969701\n",
            "final score is:  0.0015902391057786988\n",
            "final score is:  0.0006638116153193454\n",
            "final score is:  0.0011906333199402281\n",
            "final score is:  0.0013067458907162187\n",
            "final score is:  0.001632614466962216\n",
            "final score is:  0.0012096609534441253\n",
            "final score is:  0.000810791028626945\n",
            "final score is:  0.0008606575020554829\n",
            "final score is:  0.0015397637372700267\n",
            "final score is:  0.001672427264128203\n",
            "final score is:  0.001561777416593852\n",
            "final score is:  0.0007327698887768968\n",
            "final score is:  0.001399298935863709\n",
            "final score is:  0.0011257988485705987\n",
            "final score is:  0.0018802827773546499\n",
            "final score is:  0.0016176290272354767\n",
            "final score is:  0.0008651750875692586\n",
            "final score is:  0.0016184057569743637\n",
            "final score is:  0.0014122548745300252\n",
            "final score is:  0.0014364169964211256\n",
            "final score is:  0.0013519055154075361\n",
            "final score is:  0.0016278659622472897\n",
            "final score is:  0.000466843439644504\n",
            "final score is:  0.0017143271905067463\n",
            "final score is:  0.0017284276601603058\n",
            "final score is:  0.0014189421514413873\n",
            "final score is:  0.0010994484416434532\n",
            "final score is:  0.0015316783785128134\n",
            "final score is:  0.0010581821618097576\n",
            "final score is:  0.0013503365339196667\n",
            "final score is:  0.001248852334956923\n",
            "final score is:  0.0005575708449045305\n",
            "final score is:  0.0017888187945423331\n",
            "final score is:  0.0009401867422718844\n",
            "final score is:  0.001481867841085144\n",
            "final score is:  0.0005910191899602019\n",
            "final score is:  0.0012112598633562343\n",
            "final score is:  0.00118621621469484\n",
            "final score is:  0.0016139342306217992\n",
            "final score is:  0.0008601380337392717\n",
            "final score is:  0.0014107742918841848\n",
            "final score is:  0.0012026138413402544\n",
            "final score is:  0.0011873627578696214\n",
            "final score is:  0.0009103452928284636\n",
            "final score is:  0.0012073183048667033\n",
            "final score is:  0.0013246467671763093\n",
            "final score is:  0.0016593820050860844\n",
            "final score is:  0.001317712832699774\n",
            "final score is:  0.0010245297143880886\n",
            "final score is:  0.0017542500688028362\n",
            "final score is:  0.001817667786245143\n",
            "final score is:  0.0012092771619542733\n",
            "final score is:  0.0012959558837633033\n",
            "final score is:  0.001390653483099619\n",
            "final score is:  0.0013355382824604691\n",
            "final score is:  0.001462766454908431\n",
            "final score is:  0.0014143743738277874\n",
            "final score is:  0.0016321466742099107\n",
            "final score is:  0.0013137660909611412\n",
            "final score is:  0.0012754685630545959\n",
            "final score is:  0.0017456260957948095\n",
            "final score is:  0.0015606785606540228\n",
            "final score is:  0.0011480737244071112\n",
            "final score is:  0.0017073149489311252\n",
            "final score is:  0.0007433078781701391\n",
            "final score is:  0.0017185713305319958\n",
            "final score is:  0.0013408362665708077\n",
            "final score is:  0.0013404217192707645\n",
            "final score is:  0.0007124157281455012\n",
            "final score is:  0.0014789814842052316\n",
            "final score is:  0.0011004839524826838\n",
            "final score is:  0.0013207209216942795\n",
            "final score is:  0.00150799619740582\n",
            "final score is:  0.0016639438906025231\n",
            "final score is:  0.001497813144173564\n",
            "final score is:  0.0011415827612050982\n",
            "final score is:  0.0017416706401656597\n",
            "final score is:  0.000862992642182967\n",
            "final score is:  0.0015253907787729525\n",
            "final score is:  0.0008837635348741791\n",
            "final score is:  0.001266048256232125\n",
            "final score is:  0.00040961849323259213\n",
            "final score is:  0.001226403284398509\n",
            "final score is:  0.0012769933768501866\n",
            "final score is:  0.001470381931030005\n",
            "final score is:  0.0013211022823156437\n",
            "final score is:  0.0018190405550320993\n",
            "final score is:  0.000984646407704497\n",
            "final score is:  0.0016672988927242652\n",
            "final score is:  0.0012929073451384849\n",
            "final score is:  0.0016862481244730144\n",
            "final score is:  0.0014798966596101424\n",
            "final score is:  0.0010987679265636666\n",
            "final score is:  0.0010747472246706567\n",
            "final score is:  0.0012131976622538456\n",
            "final score is:  0.0013364790028428438\n",
            "final score is:  0.002027718467657296\n",
            "final score is:  0.0017142584746393573\n",
            "final score is:  0.0015853934700163837\n",
            "final score is:  0.0012676178169307834\n",
            "final score is:  0.0009399336309243789\n",
            "final score is:  0.0015933974438394466\n",
            "final score is:  0.0016114200531294315\n",
            "final score is:  0.0010963886498241383\n",
            "final score is:  0.0015127368402848454\n",
            "final score is:  0.0013068925860333952\n",
            "final score is:  0.0012397565797058886\n",
            "final score is:  0.0016894088060969456\n",
            "final score is:  0.001521234751571784\n",
            "final score is:  0.0010528796865643324\n",
            "final score is:  0.0013105484645085698\n",
            "final score is:  0.0016040967416873974\n",
            "final score is:  0.0014781928576644819\n",
            "final score is:  0.0017544429171505436\n",
            "final score is:  0.0016513194548528898\n",
            "final score is:  0.0016580278172913792\n",
            "final score is:  0.0017294417821534667\n",
            "final score is:  0.0006057256775255578\n",
            "final score is:  0.0008774222496359036\n",
            "final score is:  0.0014492345799287272\n",
            "final score is:  0.001378773681148229\n",
            "final score is:  0.001541681600521808\n",
            "final score is:  0.001388207433131618\n",
            "final score is:  0.000922373674199552\n",
            "final score is:  0.0018558861906050543\n",
            "final score is:  0.0014581716481421832\n",
            "final score is:  0.001084740699550856\n",
            "final score is:  0.0014291586998802484\n",
            "final score is:  0.0016688831329768434\n",
            "final score is:  0.0013975994476764506\n",
            "final score is:  0.0015564611640341112\n",
            "final score is:  0.0011733897462520581\n",
            "final score is:  0.0008034825340160049\n",
            "final score is:  0.0008707994409043966\n",
            "final score is:  0.0016211419665929513\n",
            "final score is:  0.0010546822931385977\n",
            "final score is:  0.0007844602896261671\n",
            "final score is:  0.0007598149570271305\n",
            "final score is:  0.0010683149470437786\n",
            "final score is:  0.0008611210983573814\n",
            "final score is:  0.0015597535897298252\n",
            "final score is:  0.0016912389963721854\n",
            "final score is:  0.001790278539797237\n",
            "final score is:  0.0018121039212147278\n",
            "final score is:  0.0011211912390775012\n",
            "final score is:  0.0008894844364737381\n",
            "final score is:  0.0014437308624744437\n",
            "final score is:  0.0012195932399957678\n",
            "final score is:  0.0015275815529270582\n",
            "final score is:  0.0009190321995002488\n",
            "final score is:  0.0011823953833471025\n",
            "final score is:  0.0012855913530269282\n",
            "final score is:  0.0016378169220753627\n",
            "final score is:  0.001627325056653827\n",
            "final score is:  0.0009929661141471267\n",
            "final score is:  0.001990754005899128\n",
            "final score is:  0.0014586569999237478\n",
            "final score is:  0.001781063468815156\n",
            "final score is:  0.001344135385249238\n",
            "final score is:  0.0020888100157796267\n",
            "final score is:  0.0014972161412487815\n",
            "final score is:  0.0012319481113277455\n",
            "final score is:  0.0010581850941990623\n",
            "final score is:  0.0011697375448490655\n",
            "final score is:  0.001493585024746147\n",
            "final score is:  0.0011663989373624298\n",
            "final score is:  0.001702123176208077\n",
            "final score is:  0.0007086151390742127\n",
            "final score is:  0.001608879776226933\n",
            "final score is:  0.001629451782029891\n",
            "final score is:  0.0014004601595399755\n",
            "final score is:  0.001510220343018993\n",
            "final score is:  0.0014317505335594354\n",
            "final score is:  0.0010920360394846781\n",
            "final score is:  0.001513584446392695\n",
            "final score is:  0.0016108820595907732\n",
            "final score is:  0.0008614389400089913\n",
            "final score is:  0.0013089830462662821\n",
            "final score is:  0.0010971249190443245\n",
            "final score is:  0.0013847148014828677\n",
            "final score is:  0.0013435188938342682\n",
            "final score is:  0.0014638781771692904\n",
            "final score is:  0.0013473878742738398\n",
            "final score is:  0.0004376159594581717\n",
            "final score is:  0.0016671912917882756\n",
            "final score is:  0.0005992602325834536\n",
            "final score is:  0.0013800709565900172\n",
            "final score is:  0.0015322694977089513\n",
            "final score is:  0.0008239295681634518\n",
            "final score is:  0.001726624126264231\n",
            "final score is:  0.0007997595854683501\n",
            "final score is:  0.0013236722967228487\n",
            "final score is:  0.0012121073563240896\n",
            "final score is:  0.0016716435155580247\n",
            "final score is:  0.0016125005311665556\n",
            "final score is:  0.0014525780497109315\n",
            "final score is:  0.0013888869466740102\n",
            "final score is:  0.0015471701272707368\n",
            "final score is:  0.0007873677458241643\n",
            "final score is:  0.0011082145117315995\n",
            "final score is:  0.0013984415571073525\n",
            "final score is:  0.001693809061221133\n",
            "final score is:  0.0013062672435072943\n",
            "final score is:  0.00130473113438002\n",
            "final score is:  0.0008424093536222422\n",
            "final score is:  0.0010665688420468916\n",
            "final score is:  0.001656188660648896\n",
            "final score is:  0.0016240263086353282\n",
            "final score is:  0.001657230462588859\n",
            "final score is:  0.0010426457784348375\n",
            "final score is:  0.0015691610921356948\n",
            "final score is:  0.0005608740426004111\n",
            "final score is:  0.0015943570889565201\n",
            "final score is:  0.0015444315887026972\n",
            "final score is:  0.0012285019907362063\n",
            "final score is:  0.0012715722598653787\n",
            "final score is:  0.001810717796889325\n",
            "final score is:  0.0017545965470666459\n",
            "final score is:  0.0015127268494190334\n",
            "final score is:  0.0014061206550113274\n",
            "final score is:  0.0017976167046626574\n",
            "final score is:  0.001706174141609297\n",
            "final score is:  0.0011061845032379297\n",
            "final score is:  0.0016897868473968963\n",
            "final score is:  0.0016930234717467886\n",
            "final score is:  0.0013622137283201927\n",
            "final score is:  0.001346428265096557\n",
            "final score is:  0.0015005408753989524\n",
            "final score is:  0.0011509663403042798\n",
            "final score is:  0.0012996088122019616\n",
            "final score is:  0.0016890595859376126\n",
            "final score is:  0.0007391816073762077\n",
            "final score is:  0.00146742420838364\n",
            "final score is:  0.0010798392586314912\n",
            "final score is:  0.0016183570892058866\n",
            "final score is:  0.0014349763067850556\n",
            "final score is:  0.0017865366517597733\n",
            "final score is:  0.0017181795914393005\n",
            "final score is:  0.0017038482590164897\n",
            "final score is:  0.0008467675383633894\n",
            "final score is:  0.0012755153615414715\n",
            "final score is:  0.0009458614339195017\n",
            "final score is:  0.0013060875320536017\n",
            "final score is:  0.001668592354178289\n",
            "final score is:  0.0006882610466508835\n",
            "final score is:  0.0016251343483238505\n",
            "final score is:  0.0011932728864453926\n",
            "final score is:  0.0013313730568241492\n",
            "final score is:  0.0006325720969683007\n",
            "final score is:  0.0010135509112601316\n",
            "final score is:  0.0006848259785459471\n",
            "final score is:  0.0012668429450608935\n",
            "final score is:  0.0012534808418611845\n",
            "final score is:  0.0009722177850974691\n",
            "final score is:  0.001506735753915004\n",
            "final score is:  0.0017198177859088669\n",
            "final score is:  0.0010892261089220658\n",
            "final score is:  0.0015777420783161366\n",
            "final score is:  0.0018217541757654943\n",
            "final score is:  0.0012573746877348054\n",
            "final score is:  0.0016789899987128603\n",
            "final score is:  0.0013939895086632083\n",
            "final score is:  0.001523678497646221\n",
            "final score is:  0.0013596055306542784\n",
            "final score is:  0.0010971963568982188\n",
            "final score is:  0.0014798542077994147\n",
            "final score is:  0.001075123395475907\n",
            "final score is:  0.0008586270349470705\n",
            "final score is:  0.0015531708404041764\n",
            "final score is:  0.0015543202702018662\n",
            "final score is:  0.0012800782557145717\n",
            "final score is:  0.0010617654540951778\n",
            "final score is:  0.0011504439580435888\n",
            "final score is:  0.0014102730055105504\n",
            "final score is:  0.0008989395486680613\n",
            "final score is:  0.001080641088037244\n",
            "final score is:  0.0018269225233037384\n",
            "final score is:  0.0015130376028498252\n",
            "final score is:  0.0015256367323249074\n",
            "final score is:  0.0016679498270642358\n",
            "final score is:  0.001382847421306965\n",
            "final score is:  0.0010430317775940172\n",
            "final score is:  0.0015968578174518724\n",
            "final score is:  0.0004951704562972958\n",
            "final score is:  0.001506704527145242\n",
            "final score is:  0.0014050151389558068\n",
            "final score is:  0.0008454469047080571\n",
            "final score is:  0.0009860143577310285\n",
            "final score is:  0.0013351906774303703\n",
            "final score is:  0.001768035160119594\n",
            "final score is:  0.0009950973508432498\n",
            "final score is:  0.0013949634510113857\n",
            "final score is:  0.001430309511106415\n",
            "final score is:  0.0013143461848687547\n",
            "final score is:  0.0016480737735871623\n",
            "final score is:  0.0012602787258915859\n",
            "final score is:  0.0014995531144355765\n",
            "final score is:  0.0015103101100314574\n",
            "final score is:  0.001527341416697929\n",
            "final score is:  0.0013611282604799734\n",
            "final score is:  0.0008680885159421557\n",
            "final score is:  0.001390164468179604\n",
            "final score is:  0.0012872446426724859\n",
            "final score is:  0.001449048794249392\n",
            "final score is:  0.001979098315933117\n",
            "final score is:  0.0014776050395103517\n",
            "final score is:  0.001588516779434144\n",
            "final score is:  0.001676568961877026\n",
            "final score is:  0.0006488785873733551\n",
            "final score is:  0.0009208863091236826\n",
            "final score is:  0.001464235899714755\n",
            "final score is:  0.0017009117165389309\n",
            "final score is:  0.0016120239756827795\n",
            "final score is:  0.0015294393378955994\n",
            "final score is:  0.0004665758229035841\n",
            "final score is:  0.0007320745635457194\n",
            "final score is:  0.0016254018348840099\n",
            "final score is:  0.0015760975543375596\n",
            "final score is:  0.0015145544016866568\n",
            "final score is:  0.0008293231298451889\n",
            "final score is:  0.0011456013323758972\n",
            "final score is:  0.0010621950675221432\n",
            "final score is:  0.0012535160924466641\n",
            "final score is:  0.0015858074564755625\n",
            "final score is:  0.0016842904476421427\n",
            "final score is:  0.0008906414346030972\n",
            "final score is:  0.0016374773298728136\n",
            "final score is:  0.0009941691135651283\n",
            "final score is:  0.001428847152643812\n",
            "final score is:  0.0009940393572170315\n",
            "final score is:  0.0018726431248486382\n",
            "final score is:  0.001587857871351796\n",
            "final score is:  0.001542196932096357\n",
            "final score is:  0.0011148592254554169\n",
            "final score is:  0.0012276452018632562\n",
            "final score is:  0.001558478026613974\n",
            "final score is:  0.001429099998736529\n",
            "final score is:  0.0012201291764854015\n",
            "final score is:  0.0016235751090916785\n",
            "final score is:  0.0016737297585300345\n",
            "final score is:  0.0013925574414400007\n",
            "final score is:  0.0014309453482512595\n",
            "final score is:  0.0018867317197050597\n",
            "final score is:  0.001436134975801661\n",
            "final score is:  0.0007425819648591035\n",
            "final score is:  0.001443983828149658\n",
            "final score is:  0.001200647321075388\n",
            "final score is:  0.0015862488667009417\n",
            "final score is:  0.0015797003194970103\n",
            "final score is:  0.0015936962834791435\n",
            "final score is:  0.0014037580061351817\n",
            "final score is:  0.0015165201785702505\n",
            "final score is:  0.0011791104735318781\n",
            "final score is:  0.0013041121207234276\n",
            "final score is:  0.001864049997553663\n",
            "final score is:  0.0014756190452949178\n",
            "final score is:  0.000764325677753345\n",
            "final score is:  0.0016503863657782625\n",
            "final score is:  0.001766532706550229\n",
            "final score is:  0.0013545866240663302\n",
            "final score is:  0.0009595333035450807\n",
            "final score is:  0.001199600663858165\n",
            "final score is:  0.0009603584820238923\n",
            "final score is:  0.0016049463009282193\n",
            "final score is:  0.0017233231531875223\n",
            "final score is:  0.001315223073125607\n",
            "final score is:  0.00153654023529762\n",
            "final score is:  0.0016378530109537356\n",
            "final score is:  0.0016100679699278572\n",
            "final score is:  0.0009485635008273539\n",
            "final score is:  0.0012471242824676784\n",
            "final score is:  0.0010726286675946746\n",
            "final score is:  0.0008786785777664872\n",
            "final score is:  0.0005794101204127714\n",
            "final score is:  0.0007971519222103672\n",
            "final score is:  0.0016448735128834536\n",
            "final score is:  0.001354618548414844\n",
            "final score is:  0.0016824811134682196\n",
            "final score is:  0.0013999552632965287\n",
            "final score is:  0.0016491643933691702\n",
            "final score is:  0.0016049742524182824\n",
            "final score is:  0.0013649895829483498\n",
            "final score is:  0.0011143913862799875\n",
            "final score is:  0.0010786501261355092\n",
            "final score is:  0.0013034993846151386\n",
            "final score is:  0.0016972674003129518\n",
            "final score is:  0.0016265522914251794\n",
            "final score is:  0.0016462224415788604\n",
            "final score is:  0.001332344739051438\n",
            "final score is:  0.0015811013126841667\n",
            "final score is:  0.0013542992869089478\n",
            "final score is:  0.0010739866825832142\n",
            "final score is:  0.0013778738711819466\n",
            "final score is:  0.001072714235907786\n",
            "final score is:  0.0016987121710426247\n",
            "final score is:  0.0012601969700428393\n",
            "final score is:  0.0012067237798148592\n",
            "final score is:  0.0006956902126276303\n",
            "final score is:  0.0012838813541037213\n",
            "final score is:  0.0011249915534519222\n",
            "final score is:  0.0011800871122638675\n",
            "final score is:  0.001254302883711841\n",
            "final score is:  0.0015150247071310584\n",
            "final score is:  0.0014598544811962287\n",
            "final score is:  0.0009792362660013304\n",
            "final score is:  0.000997380506501116\n",
            "final score is:  0.0015137037011747094\n",
            "final score is:  0.0008434219560939645\n",
            "final score is:  0.001229509328720218\n",
            "final score is:  0.001434417866535784\n",
            "final score is:  0.0017193692864544145\n",
            "final score is:  0.0015579677879223042\n",
            "final score is:  0.0015887438574898212\n",
            "final score is:  0.0013140613067288045\n",
            "final score is:  0.0015821922772861765\n",
            "final score is:  0.0019375787458617445\n",
            "final score is:  0.0014478531925475825\n",
            "final score is:  0.0014761988658010669\n",
            "final score is:  0.002047234224563814\n",
            "final score is:  0.0016870611538051113\n",
            "final score is:  0.0016300807125022901\n",
            "final score is:  0.001340915452132751\n",
            "final score is:  0.0006212583698155509\n",
            "final score is:  0.0015079084284589698\n",
            "final score is:  0.0009042760042957316\n",
            "final score is:  0.001348618408697738\n",
            "final score is:  0.0019871515984727912\n",
            "final score is:  0.0007355896747295407\n",
            "final score is:  0.0016964479650779219\n",
            "final score is:  0.0011753292659863678\n",
            "final score is:  0.0016354658315742617\n",
            "final score is:  0.001620862426313395\n",
            "final score is:  0.0017261076093740553\n",
            "final score is:  0.0013727238297722958\n",
            "final score is:  0.001191246581438844\n",
            "final score is:  0.0011604428916510824\n",
            "final score is:  0.0016197616412209478\n",
            "final score is:  0.00042665498714577305\n",
            "final score is:  0.0010231956777452178\n",
            "final score is:  0.0017679649692250235\n",
            "final score is:  0.0007761852221770619\n",
            "final score is:  0.0011940307951916374\n",
            "final score is:  0.001486368972200076\n",
            "final score is:  0.0014814277067945131\n",
            "final score is:  0.0005634644621977113\n",
            "final score is:  0.0010175689827606475\n",
            "final score is:  0.0020034892468792447\n",
            "final score is:  0.001132446306276204\n",
            "final score is:  0.001403407359664049\n",
            "final score is:  0.0014113037736565924\n",
            "final score is:  0.0014503594704161618\n",
            "final score is:  0.0015362433013881246\n",
            "final score is:  0.001393433313806541\n",
            "final score is:  0.0008358100519357785\n",
            "final score is:  0.0015238671372498661\n",
            "final score is:  0.0013881148771430851\n",
            "final score is:  0.0010905568741770533\n",
            "final score is:  0.0014892730315886594\n",
            "final score is:  0.0012758427881406536\n",
            "final score is:  0.0006462946564493412\n",
            "final score is:  0.0017968199821394063\n",
            "final score is:  0.0016728552065412444\n",
            "final score is:  0.0007155409900600349\n",
            "final score is:  0.00034797029001506575\n",
            "final score is:  0.0015253855562122874\n",
            "final score is:  0.0017294138731031882\n",
            "final score is:  0.0013188730440991231\n",
            "final score is:  0.0018401009289853822\n",
            "final score is:  0.0008083375988081635\n",
            "final score is:  0.0014974149079196367\n",
            "final score is:  0.0012738936708557127\n",
            "final score is:  0.0014190411586559278\n",
            "final score is:  0.0011806620665762342\n",
            "final score is:  0.0015844895253935675\n",
            "final score is:  0.0010668148518812625\n",
            "final score is:  0.0012257284995224789\n",
            "final score is:  0.0013572239333600243\n",
            "final score is:  0.001471457659830163\n",
            "final score is:  0.0016524077151293254\n",
            "final score is:  0.0015257402113770847\n",
            "final score is:  0.0014658069936730402\n",
            "final score is:  0.0014233162935711073\n",
            "final score is:  0.0012434761608894182\n",
            "final score is:  0.001746711740011504\n",
            "final score is:  0.0006232573514609163\n",
            "final score is:  0.0017586642271855382\n",
            "final score is:  0.0014499708028742802\n",
            "final score is:  0.0014521178604882988\n",
            "final score is:  0.001405383433620911\n",
            "final score is:  0.0015287404188648566\n",
            "final score is:  0.0012772404511072906\n",
            "final score is:  0.0008751563166776308\n",
            "final score is:  0.0011177964581173463\n",
            "final score is:  0.000658037873519349\n",
            "final score is:  0.001580854698216723\n",
            "final score is:  0.0016479846114686785\n",
            "final score is:  0.0008704120775876764\n",
            "final score is:  0.0008079460074427849\n",
            "final score is:  0.0015897138138846283\n",
            "final score is:  0.0022068439420173842\n",
            "final score is:  0.0011248002768238683\n",
            "final score is:  0.001512096630725386\n",
            "final score is:  0.0005635994443476653\n",
            "final score is:  0.0014035151813677528\n",
            "final score is:  0.0011837906501230339\n",
            "final score is:  0.0015958128742212024\n",
            "final score is:  0.0009618010704169894\n",
            "final score is:  0.0010311137608241029\n",
            "final score is:  0.0016121406704302722\n",
            "final score is:  0.0014576936956091156\n",
            "final score is:  0.001592854411201448\n",
            "final score is:  0.0012558208092517528\n",
            "final score is:  0.0014160951110897529\n",
            "final score is:  0.0007964449576079025\n",
            "final score is:  0.001068393508825534\n",
            "final score is:  0.0015432816132871108\n",
            "final score is:  0.00048462640014428326\n",
            "final score is:  0.0012301013439839298\n",
            "final score is:  0.0009768052212960447\n",
            "final score is:  0.0009476088306598106\n",
            "final score is:  0.0016976874444709356\n",
            "final score is:  0.0011115913983095655\n",
            "final score is:  0.001478506071931779\n",
            "final score is:  0.0013194282314868055\n",
            "final score is:  0.0013292902227410935\n",
            "final score is:  0.0015236457789853163\n",
            "final score is:  0.0013285273503210898\n",
            "final score is:  0.0017836559322387806\n",
            "final score is:  0.0017075005460032789\n",
            "final score is:  0.0008591455060998788\n",
            "final score is:  0.0012012940673668505\n",
            "final score is:  0.0005925128733725461\n",
            "final score is:  0.0019159811876699113\n",
            "final score is:  0.0005552844067377502\n",
            "final score is:  0.001798471091934933\n",
            "final score is:  0.0018636136565363228\n",
            "final score is:  0.0015126879790610006\n",
            "final score is:  0.001479103775242942\n",
            "final score is:  0.001228378673068487\n",
            "final score is:  0.0009587245861513488\n",
            "final score is:  0.0013619551452340123\n",
            "final score is:  0.0014931921615585558\n",
            "final score is:  0.0007114514092526091\n",
            "final score is:  0.0012462506111558234\n",
            "final score is:  0.0013728495018321871\n",
            "final score is:  0.001318333664997047\n",
            "final score is:  0.0015057253105521973\n",
            "final score is:  0.0003719502306266035\n",
            "final score is:  0.0010872024563051358\n",
            "final score is:  0.0014088360313471045\n",
            "final score is:  0.0014894666241728107\n",
            "final score is:  0.0019800787509362114\n",
            "final score is:  0.0010942106988189313\n",
            "final score is:  0.0014855482044959772\n",
            "final score is:  0.0015971299634142512\n",
            "final score is:  0.0014318382626161074\n",
            "final score is:  0.0006896435510732188\n",
            "final score is:  0.0014661274385663256\n",
            "final score is:  0.0012917990091955763\n",
            "final score is:  0.0016228589095695898\n",
            "final score is:  0.001158994839814932\n",
            "final score is:  0.0014906141155583419\n",
            "final score is:  0.0013365175085530638\n",
            "final score is:  0.0017706933603615375\n",
            "final score is:  0.0012858772998507986\n",
            "final score is:  0.0014175517633632296\n",
            "final score is:  0.0018058485889343022\n",
            "final score is:  0.0014037476126297225\n",
            "final score is:  0.0012608850318860073\n",
            "final score is:  0.0008432198801864234\n",
            "final score is:  0.0014738573577893499\n",
            "final score is:  0.0012118236994817838\n",
            "final score is:  0.001112482106331504\n",
            "final score is:  0.0013380635667422287\n",
            "final score is:  0.001528727756435479\n",
            "final score is:  0.0017311763566537357\n",
            "final score is:  0.0018146564956150347\n",
            "final score is:  0.0008012848361362317\n",
            "final score is:  0.0017862633666706638\n",
            "final score is:  0.0012301778232160219\n",
            "final score is:  0.0017595757422311008\n",
            "final score is:  0.001226825678658402\n",
            "final score is:  0.0017560041986093972\n",
            "final score is:  0.0016328819990379063\n",
            "final score is:  0.0015419509338825243\n",
            "final score is:  0.0012637828220198098\n",
            "final score is:  0.0012755451406226508\n",
            "final score is:  0.0014860034130645473\n",
            "final score is:  0.0012182386264710731\n",
            "final score is:  0.0006804760205393748\n",
            "final score is:  0.0017326141441738965\n",
            "final score is:  0.0016489508738237908\n",
            "final score is:  0.0006538066955005749\n",
            "final score is:  0.0019091644263521598\n",
            "final score is:  0.0007789547652177074\n",
            "final score is:  0.0015925050759416097\n",
            "final score is:  0.001247555225852081\n",
            "final score is:  0.0014123025273693076\n",
            "final score is:  0.0017534569737380915\n",
            "final score is:  0.0014907371984009634\n",
            "final score is:  0.0012898612503166478\n",
            "final score is:  0.0017321849282080466\n",
            "final score is:  0.001509296293657096\n",
            "final score is:  0.0019364553072609145\n",
            "final score is:  0.0015723527960931976\n",
            "final score is:  0.0011165573821001688\n",
            "final score is:  0.001852169401656777\n",
            "final score is:  0.0013909164842476841\n",
            "final score is:  0.001612477708995739\n",
            "final score is:  0.0009077791062181447\n",
            "final score is:  0.0013570732848181475\n",
            "final score is:  0.0014963000120095755\n",
            "final score is:  0.0013019417121499816\n",
            "final score is:  0.000998970803932372\n",
            "final score is:  0.0017850474952525275\n",
            "final score is:  0.0009510421464735701\n",
            "final score is:  0.0017563433456083454\n",
            "final score is:  0.0014376811194869268\n",
            "final score is:  0.0008201878323663175\n",
            "final score is:  0.0011494531723407685\n",
            "final score is:  0.0014875252091582731\n",
            "final score is:  0.0022150474259325426\n",
            "final score is:  0.0017879025380781787\n",
            "final score is:  0.001360274860379382\n",
            "final score is:  0.0007886854316416309\n",
            "final score is:  0.001229204276625033\n",
            "final score is:  0.0007224855701205082\n",
            "final score is:  0.0018709818872647607\n",
            "final score is:  0.0015775326166573246\n",
            "final score is:  0.001568016884328341\n",
            "final score is:  0.0015332413687501418\n",
            "final score is:  0.0016510156555565965\n",
            "final score is:  0.001923163219087333\n",
            "final score is:  0.0007448994372399193\n",
            "final score is:  0.0016433551199021314\n",
            "final score is:  0.0008368088382201826\n",
            "final score is:  0.0015388448654929559\n",
            "final score is:  0.0016286833919188282\n",
            "final score is:  0.0012817264350830733\n",
            "final score is:  0.0008401186916079116\n",
            "final score is:  0.0012659484504574873\n",
            "final score is:  0.001486782599933111\n",
            "final score is:  0.0013356740813229902\n",
            "final score is:  0.0008554876461538156\n",
            "final score is:  0.0012100243303950593\n",
            "final score is:  0.0011632434815278913\n",
            "final score is:  0.0016305462563905501\n",
            "final score is:  0.0009651808568542426\n",
            "final score is:  0.0009782620609001173\n",
            "final score is:  0.00030947997785693847\n",
            "final score is:  0.0013050644832773206\n",
            "final score is:  0.001614301542129401\n",
            "final score is:  0.0016058717850343986\n",
            "final score is:  0.001440980820766904\n",
            "final score is:  0.0014094542697022981\n",
            "final score is:  0.00166648588647538\n",
            "final score is:  0.0013632118461330842\n",
            "final score is:  0.0015827402677269264\n",
            "final score is:  0.001743351126515396\n",
            "final score is:  0.00196259464606334\n",
            "final score is:  0.0009528793355948082\n",
            "final score is:  0.0010747207282143592\n",
            "final score is:  0.0013847206964292403\n",
            "final score is:  0.0019650997635453815\n",
            "final score is:  0.0012289330899030394\n",
            "final score is:  0.0014327516466817092\n",
            "final score is:  0.0018266318017575152\n",
            "final score is:  0.0004966491193041255\n",
            "final score is:  0.0013677159243502225\n",
            "final score is:  0.0013414398736298191\n",
            "final score is:  0.0016869974624666984\n",
            "final score is:  0.0010584001490303245\n",
            "final score is:  0.0014178126795309398\n",
            "final score is:  0.0015900644668689603\n",
            "final score is:  0.0012482598124137546\n",
            "final score is:  0.0014910357792922019\n",
            "final score is:  0.0014283216477911386\n",
            "final score is:  0.001302982611918305\n",
            "final score is:  0.0014671604302696221\n",
            "final score is:  0.0018353236203585352\n",
            "final score is:  0.0014776117488063698\n",
            "final score is:  0.0013245337368116212\n",
            "final score is:  0.0020074624642854835\n",
            "final score is:  0.001618028516090389\n",
            "final score is:  0.0013357519266508089\n",
            "final score is:  0.0015810631381543104\n",
            "final score is:  0.0012261133645493382\n",
            "final score is:  0.001742733987198692\n",
            "final score is:  0.0016528922724695074\n",
            "final score is:  0.0016603796246536288\n",
            "final score is:  0.0012582944740795459\n",
            "final score is:  0.0013861382827877937\n",
            "final score is:  0.0014796157326636354\n",
            "final score is:  0.0017648778965178918\n",
            "final score is:  0.0007513305478731304\n",
            "final score is:  0.0013536678385430438\n",
            "final score is:  0.0016287588728994575\n",
            "final score is:  0.0012207802852896564\n",
            "final score is:  0.0015613797756853394\n",
            "final score is:  0.0016345773126520858\n",
            "final score is:  0.001496106848824118\n",
            "final score is:  0.0016438635108331975\n",
            "final score is:  0.0010508227187034324\n",
            "final score is:  0.0006803892974591598\n",
            "final score is:  0.00139915725257319\n",
            "final score is:  0.0014091285729448484\n",
            "final score is:  0.0012386329743853401\n",
            "final score is:  0.001353181907235218\n",
            "final score is:  0.001707291760814137\n",
            "final score is:  0.0018030033937163805\n",
            "final score is:  0.001425191129060379\n",
            "final score is:  0.0010708679180703978\n",
            "final score is:  0.0008699454590069075\n",
            "final score is:  0.0009763994487521759\n",
            "final score is:  0.0011935159394267552\n",
            "final score is:  0.00126327478837972\n",
            "final score is:  0.0012418906653400166\n",
            "final score is:  0.0010748867515209515\n",
            "final score is:  0.0013376465781933986\n",
            "final score is:  0.0011194507009774756\n",
            "final score is:  0.0014203272840214267\n",
            "final score is:  0.0010654869121347142\n",
            "final score is:  0.001048668156067838\n",
            "final score is:  0.001173068852384501\n",
            "final score is:  0.0010522061842740912\n",
            "final score is:  0.0016300721337232428\n",
            "final score is:  0.0010628304466297842\n",
            "final score is:  0.0013026563359073663\n",
            "final score is:  0.0009152945264171378\n",
            "final score is:  0.0017491764741062652\n",
            "final score is:  0.0013575280662804932\n",
            "final score is:  0.0006948527015850411\n",
            "final score is:  0.0014616235249105096\n",
            "final score is:  0.0012555202723247723\n",
            "final score is:  0.0016791365305365913\n",
            "final score is:  0.0009511049828746017\n",
            "final score is:  0.001166944826272061\n",
            "final score is:  0.001579256895527262\n",
            "final score is:  0.0015113712073917666\n",
            "final score is:  0.0008527344530262108\n",
            "final score is:  0.0010075360394639057\n",
            "final score is:  0.0023177385423387557\n",
            "final score is:  0.001691071484209723\n",
            "final score is:  0.0013824417948485046\n",
            "final score is:  0.0015415631698744046\n",
            "final score is:  0.0013967350596374535\n",
            "final score is:  0.0016752678553231207\n",
            "final score is:  0.002110041679293509\n",
            "final score is:  0.0009134307873040769\n",
            "final score is:  0.00040429635805019817\n",
            "final score is:  0.00082254865068255\n",
            "final score is:  0.0016283702250113408\n",
            "final score is:  0.0012526852721416104\n",
            "final score is:  0.0012574270656149431\n",
            "final score is:  0.0017146786078459076\n",
            "final score is:  0.0017754892617874321\n",
            "final score is:  0.0014900179481294748\n",
            "final score is:  0.00151524030310373\n",
            "final score is:  0.0016390835168447798\n",
            "final score is:  0.0015742573516985441\n",
            "final score is:  0.001295699976159669\n",
            "final score is:  0.001415233300426419\n",
            "final score is:  0.0015940885504748309\n",
            "final score is:  0.0019251645588139877\n",
            "final score is:  0.000878221246123193\n",
            "final score is:  0.001248246925836144\n",
            "final score is:  0.0014534562512996004\n",
            "final score is:  0.001308549878850033\n",
            "final score is:  0.0018120504471953163\n",
            "final score is:  0.001003893094333772\n",
            "final score is:  0.000714506115589124\n",
            "final score is:  0.001106940017873238\n",
            "final score is:  0.001315302382395262\n",
            "final score is:  0.0013480717827374135\n",
            "final score is:  0.0010280216370613454\n",
            "final score is:  0.001483789506526732\n",
            "final score is:  0.0016379631286883392\n",
            "final score is:  0.00085353206624431\n",
            "final score is:  0.0012347178426323083\n",
            "final score is:  0.0015123244467483768\n",
            "final score is:  0.0017742035205811253\n",
            "final score is:  0.0005399179770227707\n",
            "final score is:  0.0012199819658523263\n",
            "final score is:  0.0013085304158099399\n",
            "final score is:  0.0012177600354857014\n",
            "final score is:  0.0008726103665643021\n",
            "final score is:  0.0013609971802704135\n",
            "final score is:  0.0015186417925198232\n",
            "final score is:  0.0017610062283436839\n",
            "final score is:  0.0011212664513097063\n",
            "final score is:  0.0010918841681626188\n",
            "final score is:  0.0015575944651178525\n",
            "final score is:  0.0014373048393174779\n",
            "final score is:  0.0011446284914674513\n",
            "final score is:  0.0013019002542892092\n",
            "final score is:  0.0013732226609653\n",
            "final score is:  0.0012857579847999874\n",
            "final score is:  0.0012936735148783426\n",
            "final score is:  0.001387161837745601\n",
            "final score is:  0.001307003450102934\n",
            "final score is:  0.0017708756206747914\n",
            "final score is:  0.0013090447938253161\n",
            "final score is:  0.0013250779722877928\n",
            "final score is:  0.001612667237426265\n",
            "final score is:  0.0018706247481282189\n",
            "final score is:  0.0011054322732031237\n",
            "final score is:  0.0012567748771428985\n",
            "final score is:  0.0012747261430047783\n",
            "final score is:  0.0013344001988572203\n",
            "final score is:  0.0007287555497302077\n",
            "final score is:  0.0009309412340457176\n",
            "final score is:  0.001023400891444441\n",
            "final score is:  0.0015091958923325814\n",
            "final score is:  0.0013597907185414323\n",
            "final score is:  0.001644426873027176\n",
            "final score is:  0.0017576235608191264\n",
            "final score is:  0.0015351221146477749\n",
            "final score is:  0.0015120851763958728\n",
            "final score is:  0.0009424717652657465\n",
            "final score is:  0.0015401596737481735\n",
            "final score is:  0.0011802162412094608\n",
            "final score is:  0.002061519873136301\n",
            "final score is:  0.0009197324530797143\n",
            "final score is:  0.0018658666573284936\n",
            "final score is:  0.0011974891728468886\n",
            "final score is:  0.0012794630488112185\n",
            "final score is:  0.0012858367092949373\n",
            "final score is:  0.001140070060518995\n",
            "final score is:  0.0009417943167948634\n",
            "final score is:  0.0014094948929492934\n",
            "final score is:  0.001670589116885846\n",
            "final score is:  0.0008152372549935838\n",
            "final score is:  0.0013802472436764024\n",
            "final score is:  0.0012247124844872712\n",
            "final score is:  0.0010439448961883577\n",
            "final score is:  0.0016182841562962602\n",
            "final score is:  0.0014053373258757587\n",
            "final score is:  0.001127951050398892\n",
            "final score is:  0.0010618129490573545\n",
            "final score is:  0.001224727884747689\n",
            "final score is:  0.0019421836431818993\n",
            "final score is:  0.0018068579988800516\n",
            "final score is:  0.0015649964144439387\n",
            "0.0023177385423387557 898 0.0023177385423387557\n"
          ]
        }
      ],
      "source": [
        "# score\n",
        "\n",
        "scores = []\n",
        "\n",
        "n_rep = 1000\n",
        "n_selected_features = 30\n",
        "all_selected_features = []\n",
        "\n",
        "for j in range (n_rep):\n",
        "  selected_features = random.sample(range(group_features_both_val.shape[-1]), 10)\n",
        "  all_selected_features.append(selected_features)\n",
        "\n",
        "  group_1 = group_features_class1[:,selected_features]\n",
        "  group_2 = group_features_class2[:,selected_features]\n",
        "  both_groups = group_features_both[:, selected_features]\n",
        "\n",
        "  S1 = np.zeros((group_1.shape[1],group_1.shape[1]))\n",
        "  S2 = np.zeros((group_2.shape[1],group_2.shape[1]))\n",
        "\n",
        "  n_trials = 50\n",
        "  n_class = 2\n",
        "  for i in range(n_trials):\n",
        "    S1 += (group_1[i,:] - np.mean(group_1, axis=0)) @ (group_1[i,:] - np.mean(group_1, axis=0)).T\n",
        "    S2 += (group_2[i,:] - np.mean(group_2, axis=0)) @ (group_2[i,:] - np.mean(group_2, axis=0)).T\n",
        "\n",
        "  S1 /= n_trials\n",
        "  S2 /= n_trials  \n",
        "\n",
        "  Sw = S1+S2\n",
        "\n",
        "  # between class matrix\n",
        "  Sb = np.zeros((group_1.shape[1],group_1.shape[1]))\n",
        "\n",
        "  mean_all = np.expand_dims(np.mean(both_groups, axis=0), axis=1)\n",
        "  mean_class1 = np.expand_dims(np.mean(group_1, axis=0), axis=1)\n",
        "  mean_class2 = np.expand_dims(np.mean(group_2, axis=0), axis=1)\n",
        "\n",
        "  Sb = ((mean_class1-mean_all) @ (mean_class1-mean_all).T) + ((mean_class2-mean_all) @ (mean_class2-mean_all).T)\n",
        "\n",
        "\n",
        "  # final score\n",
        "  J = np.trace(Sb)/np.trace(Sw)\n",
        "  print('final score is: ', J)\n",
        "  scores.append(J)\n",
        "\n",
        "print(np.max(scores), np.argmax(scores), scores[np.argmax(scores)])\n",
        "\n",
        "target_feature = all_selected_features[np.argmax(scores)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPrFzslae1_m",
        "outputId": "1a669758-2141-4a15-d5ff-137177aa6bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2) (20, 2)\n"
          ]
        }
      ],
      "source": [
        "# change y to one hot labels\n",
        "# we have 2 classes, so our MLP will have 2 output neurons which one neuron \n",
        "# will be one and the others zero\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_tr_hot = to_categorical(Train_Label)\n",
        "y_val_hot = to_categorical(Val_Label)\n",
        "\n",
        "print(y_tr_hot.shape, y_val_hot.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the K-fold Cross Validator\n",
        "# Setting up the layers\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Softmax\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "final_features = group_features_both[:,target_feature]\n",
        "\n",
        "\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "input_layer_size = group_features_both[:,target_feature].shape[1]\n",
        "for train, test in kfold.split(final_features, y_tr_hot):\n",
        "  # CREATE MLP MODEL\n",
        "  # Setting up the layers\n",
        "\n",
        "\n",
        "\n",
        "  model = keras.Sequential([\n",
        "                        Input(shape = (input_layer_size,)), # input layer\n",
        "                        Dense(units = 10), # hidden layer one\n",
        "                        Activation(activation = tf.math.tanh),\n",
        "                        Dense(units = 10), # hidden layer two\n",
        "                        Activation(activation = tf.math.tanh),\n",
        "                        Dense(units = 2), # output layer\n",
        "                        Softmax(axis = 1)\n",
        "  ])\n",
        "\n",
        "  # Compling the model\n",
        "\n",
        "  # make our model ready for training\n",
        "  # 1. optimizer 2. loss function 3. metrics\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = keras.optimizers.SGD(learning_rate=0.001),\n",
        "      loss = keras.losses.CategoricalCrossentropy(),\n",
        "      metrics = ['accuracy']\n",
        "  )\n",
        "\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "\n",
        "  hist = model.fit(\n",
        "      final_features[train],\n",
        "      y_tr_hot[train],\n",
        "      batch_size=5,\n",
        "  )\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(final_features[test], y_tr_hot[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Evaluations, test the model on test data using keras\n",
        "  results = model.evaluate(group_features_both_val[:,target_feature], y_val_hot)\n",
        "\n",
        "  print(results)\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQIcJeRkAKGz",
        "outputId": "88a2f886-6d8b-4bd9-ba5b-2cd531484de5"
      },
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for fold 1 ...\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9667 - accuracy: 0.4125\n",
            "Score for fold 1: loss of 0.7290371656417847; accuracy of 55.000001192092896%\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.7900 - accuracy: 0.5000\n",
            "[0.7899616956710815, 0.5]\n",
            "Training for fold 2 ...\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.7963 - accuracy: 0.5000\n",
            "Score for fold 2: loss of 0.7949598431587219; accuracy of 60.00000238418579%\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7611 - accuracy: 0.5500\n",
            "[0.7610810995101929, 0.550000011920929]\n",
            "Training for fold 3 ...\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.4750\n",
            "Score for fold 3: loss of 0.6460062861442566; accuracy of 64.99999761581421%\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6889 - accuracy: 0.5500\n",
            "[0.6889074444770813, 0.550000011920929]\n",
            "Training for fold 4 ...\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7663 - accuracy: 0.4875\n",
            "Score for fold 4: loss of 0.8319150805473328; accuracy of 34.99999940395355%\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7013 - accuracy: 0.5500\n",
            "[0.7013451457023621, 0.550000011920929]\n",
            "Training for fold 5 ...\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8483 - accuracy: 0.4750\n",
            "Score for fold 5: loss of 0.7567371129989624; accuracy of 60.00000238418579%\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8686 - accuracy: 0.4000\n",
            "[0.8685692548751831, 0.4000000059604645]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHKzHNENpyu6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CI Project",
      "provenance": [],
      "authorship_tag": "ABX9TyOzNZx3Ci7aes5ivchXl+aF"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}